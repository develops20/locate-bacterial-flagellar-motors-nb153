{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":91249,"databundleVersionId":11294684,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nicholas33/byu-2-locate-bacterial-flagellar-motors-nb153?scriptVersionId=241155909\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# Install required packages\n!pip install retrying monai scipy scikit-image wandb imageio gcsfs\n\n# Import libraries\nimport os\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom monai.networks.nets import UNet\nfrom monai.losses import DiceLoss\nimport torch.optim as optim\nfrom scipy.ndimage import gaussian_filter, center_of_mass\nfrom scipy.signal import find_peaks\nimport sklearn.metrics\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport glob\nfrom IPython.display import Video, display\nimport wandb\nimport time\nimport shutil\nimport gcsfs  # Dataset is too big for kaggle - After multiple attempts of uploading, I failed miserably. \nimport gc\nimport threading\nimport logging\nimport sys\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nimport queue\nfrom retrying import retry\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\n# Set random seed for reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:06:29.236149Z","iopub.execute_input":"2025-05-22T02:06:29.236408Z","iopub.status.idle":"2025-05-22T02:08:29.230808Z","shell.execute_reply.started":"2025-05-22T02:06:29.236389Z","shell.execute_reply":"2025-05-22T02:08:29.230069Z"}},"outputs":[{"name":"stdout","text":"Collecting retrying\n  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\nCollecting monai\n  Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.2)\nRequirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\nRequirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.9)\nRequirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (2.37.0)\nRequirement already satisfied: gcsfs in /usr/local/lib/python3.11/dist-packages (2025.3.2)\nRequirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from retrying) (1.17.0)\nRequirement already satisfied: numpy<2.0,>=1.24 in /usr/local/lib/python3.11/dist-packages (from monai) (1.26.4)\nRequirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from monai) (2.6.0+cu124)\nRequirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.4.2)\nRequirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (11.1.0)\nRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.3.30)\nRequirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (25.0)\nRequirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (7.0.0)\nRequirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.25.1)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\nRequirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from gcsfs) (3.11.18)\nRequirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.11/dist-packages (from gcsfs) (4.4.2)\nRequirement already satisfied: fsspec==2025.3.2 in /usr/local/lib/python3.11/dist-packages (from gcsfs) (2025.3.2)\nRequirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.11/dist-packages (from gcsfs) (2.40.1)\nRequirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.11/dist-packages (from gcsfs) (1.2.1)\nRequirement already satisfied: google-cloud-storage in /usr/local/lib/python3.11/dist-packages (from gcsfs) (2.19.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.20.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs) (4.9.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.24->monai) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.24->monai) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.24->monai) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.24->monai) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.24->monai) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.24->monai) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.18.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.9->monai)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.9->monai)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.9->monai)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.9->monai)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.9->monai)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.9->monai)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.9->monai)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->monai) (1.3.0)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib->gcsfs) (2.0.0)\nCollecting google-api-core<3.0.0dev,>=2.15.0 (from google-cloud-storage->gcsfs)\n  Downloading google_api_core-2.24.2-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs) (2.4.3)\nRequirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs) (2.7.2)\nRequirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs) (1.7.1)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\nRequirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs) (1.70.0)\nRequirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs) (1.26.1)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.6.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.2.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->monai) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.24->monai) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.24->monai) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0,>=1.24->monai) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0,>=1.24->monai) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0,>=1.24->monai) (2024.2.0)\nDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\nDownloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading google_api_core-2.24.2-py3-none-any.whl (160 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: retrying, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, google-api-core, monai\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n  Attempting uninstall: google-api-core\n    Found existing installation: google-api-core 1.34.1\n    Uninstalling google-api-core-1.34.1:\n      Successfully uninstalled google-api-core-1.34.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.24.2 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed google-api-core-2.24.2 monai-1.4.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 retrying-1.3.4\n","output_type":"stream"},{"name":"stderr","text":"<frozen importlib._bootstrap_external>:1241: FutureWarning: The cuda.cudart module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.runtime module instead.\n2025-05-22 02:08:15.463356: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747879695.646889      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747879695.702835      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Ensure the output directory exists\nos.makedirs('/kaggle/working', exist_ok=True)\n\n# Clear any existing handlers to avoid conflicts\nlogging.getLogger().handlers = []\nlogger = logging.getLogger('training') #Root logger \nlogger.setLevel(logging.WARNING)\n# Create and configure FileHandler\nfile_handler = logging.FileHandler(\"/kaggle/working/training.log\", mode='w')  # Truncate mode\nfile_handler.setLevel(logging.WARNING)\nfile_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n# Add handler to logger\nlogger.addHandler(file_handler)\n# Console handler\nconsole_handler = logging.StreamHandler(sys.stdout)\nconsole_handler.setLevel(logging.WARNING)\nconsole_handler.setFormatter(logging.Formatter('%(levelname)s - %(message)s'))\nlogger.addHandler(console_handler)\n\n# Suppress external library logs\nlogging.getLogger('gcsfs').setLevel(logging.ERROR)\nlogging.getLogger('torch').setLevel(logging.ERROR)\nlogging.getLogger('monai').setLevel(logging.ERROR)\nlogging.getLogger('numpy').setLevel(logging.ERROR)\n\n# Conditional INFO logging\ndef log_info(message, force=False):\n    if force or 'first_epoch' in globals() and first_epoch:\n        logger.info(message)\n\n# Force flush to ensure logs are written\nfile_handler.flush()\nfile_handler.stream.flush()\n\n# Brief delay to ensure file write completes\ntime.sleep(0.1)\n\n# Verify file contents\ntry:\n    with open(\"/kaggle/working/training.log\", \"r\") as f:\n        contents = f.read()\n        print(f\"Initial log file contents: {contents}\", flush=True)\nexcept FileNotFoundError:\n    print(\"training.log not found\", flush=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:08:38.336194Z","iopub.execute_input":"2025-05-22T02:08:38.336937Z","iopub.status.idle":"2025-05-22T02:08:38.447144Z","shell.execute_reply.started":"2025-05-22T02:08:38.336906Z","shell.execute_reply":"2025-05-22T02:08:38.446567Z"}},"outputs":[{"name":"stdout","text":"Initial log file contents: \n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Initialize wandb\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nwb_token = user_secrets.get_secret(\"WANDB\")\nwandb.login(key=wb_token)\nwandb.init(\n    project=\"byu-bacterial-flagellar-motors\",\n    config={\n        \"learning_rate\": 1e-3,\n        \"epochs\": 50,\n        \"batch_size\": 4,\n        \"patch_size\": (128, 128, 128),\n        \"gaussian_sigma\": 5,\n        \"architecture\": \"3D U-Net\",\n        \"optimizer\": \"Adam\",\n        \"loss_function\": \"DiceLoss\",\n        \"beta\": 2\n    }\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fs = gcsfs.GCSFileSystem(token=\"anon\") # Initialize GCS filesystem\n\n# Define GCS path and local directory\ngcs_precomputed_path = \"gs://nb153/precomputedmasks\"\ngcs_preprocessed_path = \"gs://nb153/preprocessed\"\nlocal_dir = \"/kaggle/working/data\"\nos.makedirs(local_dir, exist_ok=True)\n\n# Device configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:08:44.516964Z","iopub.execute_input":"2025-05-22T02:08:44.517239Z","iopub.status.idle":"2025-05-22T02:08:44.522812Z","shell.execute_reply.started":"2025-05-22T02:08:44.51722Z","shell.execute_reply":"2025-05-22T02:08:44.522123Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# 1. Analyze dataset to identify tomograms with motors\ndef identify_motor_tomograms(labels_df):\n    \"\"\"Identify tomograms with valid motor annotations.\"\"\"\n    motor_tomograms = []\n    for tomo_id in labels_df[\"tomo_id\"].unique():\n        tomo_labels = labels_df[labels_df[\"tomo_id\"] == tomo_id].iloc[0]\n        if tomo_labels[\"Number of motors\"] > 0 and tomo_labels[\"Motor axis 0\"] != -1:\n            motor_tomograms.append(tomo_id)\n    logger.info(f\"Found {len(motor_tomograms)} tomograms with motors\")\n    return motor_tomograms\n\n\n# Load labels and identify motor tomograms\nlabels_df = pd.read_csv(\"/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/train_labels.csv\")\ntomo_ids = sorted(labels_df[\"tomo_id\"].unique())\nmotor_tomo_ids = identify_motor_tomograms(labels_df)  # 2. Store tomogram IDs with motors\nlogger.info(f\"Total tomograms: {len(tomo_ids)}, Motor tomograms: {len(motor_tomo_ids)}\")\n\n# Split into train/val/test (80/10/10) using only motor tomograms for training\ntrain_val_ids, test_ids = train_test_split(tomo_ids, test_size=0.1, random_state=42)\ntrain_ids, val_ids = train_test_split(train_val_ids, test_size=0.1111, random_state=42)\ntrain_ids = [tid for tid in train_ids if tid in motor_tomo_ids]  # 3. Use only motor tomograms for training\nlogger.info(f\"Train IDs: {len(train_ids)}, Val IDs: {len(val_ids)}, Test IDs: {len(test_ids)}\")\n\n# Analyze tomograms and print motor statistics\ndef analyze_tomograms(labels_df):\n    total_tomograms = len(labels_df[\"tomo_id\"].unique())\n    motor_tomograms = len(labels_df[labels_df[\"Number of motors\"] > 0])\n    non_motor_tomograms = total_tomograms - motor_tomograms\n    print(f\"Total tomograms: {total_tomograms}\", flush=True)\n    print(f\"Tomograms with motors: {motor_tomograms}\", flush=True)\n    print(f\"Tomograms without motors: {non_motor_tomograms}\", flush=True)\n    logger.info(f\"Total tomograms: {total_tomograms}\")\n    logger.info(f\"Tomograms with motors: {motor_tomograms}\")\n    logger.info(f\"Tomograms without motors: {non_motor_tomograms}\")\n    return total_tomograms, motor_tomograms, non_motor_tomograms\n\n# Plot tomogram distribution\ndef plot_tomogram_distribution(labels_df):\n    total_tomograms = len(labels_df[\"tomo_id\"].unique())\n    motor_tomograms = len(labels_df[labels_df[\"Number of motors\"] > 0])\n    non_motor_tomograms = total_tomograms - motor_tomograms\n    plt.figure(figsize=(8, 5))\n    plt.bar([\"Total\", \"With Motors\", \"Without Motors\"], [total_tomograms, motor_tomograms, non_motor_tomograms], color=[\"blue\", \"green\", \"red\"])\n    plt.title(\"Tomogram Distribution\")\n    plt.ylabel(\"Count\")\n    for i, count in enumerate([total_tomograms, motor_tomograms, non_motor_tomograms]):\n        plt.text(i, count + 0.5, str(count), ha=\"center\")\n    plt.show()\n    plt.close()\n\n# Download functions with simultaneous downloading\ndef download_npy_and_mask(tomo_id, gcs_preprocessed_path, gcs_precomputed_path, split, local_dir):\n    \"\"\"Download tomogram and mask simultaneously using threads.\"\"\"\n    def download_npy():\n        gcs_file_path = f\"{gcs_preprocessed_path}/{split}/{tomo_id}/{tomo_id}.npy\"\n        local_file_path = os.path.join(local_dir, f\"{tomo_id}.npy\")\n        if not os.path.exists(local_file_path):\n            logger.info(f\"Downloading {gcs_file_path} to {local_file_path}\")\n            fs.get(gcs_file_path, local_file_path)\n            logger.info(f\"✅ Download complete: {tomo_id}\")\n\n    def download_mask():\n        gcs_file_path = f\"{gcs_precomputed_path}/{split}/{tomo_id}_mask.npy\"\n        local_file_path = os.path.join(local_dir, f\"{tomo_id}_mask.npy\")\n        if not os.path.exists(local_file_path):\n            logger.info(f\"Downloading {gcs_file_path} to {local_file_path}\")\n            fs.get(gcs_file_path, local_file_path)\n            logger.info(f\"✅ Download complete: {tomo_id}_mask.npy\")\n\n    # Run downloads in parallel\n    t1 = threading.Thread(target=download_npy)\n    t2 = threading.Thread(target=download_mask)\n    t1.start(); t2.start()\n    t1.join(); t2.join()\n    logger.info(f\"Completed downloading tomogram and mask for {tomo_id}\")\n    return os.path.join(local_dir, f\"{tomo_id}.npy\"), os.path.join(local_dir, f\"{tomo_id}_mask.npy\")\n\n\n# Combined download and preprocess function\ndef download_and_preprocess(tomo_id, gcs_preprocessed_path, gcs_precomputed_path, split, local_dir, labels_df, patches_per_volume):\n    try:\n        tomo_path, mask_path = download_npy_and_mask(tomo_id, gcs_preprocessed_path, gcs_precomputed_path, split, local_dir)\n        logger.warning(f\"Completed parallel download for tomogram {tomo_id}\")\n        volume = np.load(tomo_path)\n        mask = np.load(mask_path)\n        tomo_labels = labels_df[labels_df[\"tomo_id\"] == tomo_id].iloc[0]\n        num_motors = tomo_labels[\"Number of motors\"]\n        log_info(f\"Tomogram {tomo_id} has {num_motors} motors\")\n        patches, mask_patches = sample_patches(tomo_id, volume, mask, labels_df, patches_per_volume=patches_per_volume)\n        del volume, mask\n        logger.warning(f\"Prepared patches for tomogram {tomo_id}\")\n        return tomo_id, patches, mask_patches\n    except Exception as e:\n        logger.error(f\"Error processing tomogram {tomo_id}: {str(e)}\")\n        raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:08:46.744716Z","iopub.execute_input":"2025-05-22T02:08:46.745003Z","iopub.status.idle":"2025-05-22T02:08:47.002646Z","shell.execute_reply.started":"2025-05-22T02:08:46.744981Z","shell.execute_reply":"2025-05-22T02:08:47.002152Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Sample patches\ndef sample_patches(tomo_id, volume, mask, labels_df, patch_size=(128, 128, 128), patches_per_volume=32):\n    shape = volume.shape\n    patches = []\n    mask_patches = []\n    tomo_labels = labels_df[labels_df[\"tomo_id\"] == tomo_id]\n    motor_coords = []\n    for _, row in tomo_labels.iterrows():\n        if row[\"Number of motors\"] > 0 and row[\"Motor axis 0\"] != -1:\n            z, y, x = int(row[\"Motor axis 0\"]), int(row[\"Motor axis 1\"]), int(row[\"Motor axis 2\"])\n            if 0 <= z < shape[0] and 0 <= y < shape[1] and 0 <= x < shape[2]:\n                motor_coords.append((z, y, x))\n    \n    for _ in range(patches_per_volume // 2):\n        if motor_coords:\n            zc, yc, xc = motor_coords[np.random.randint(len(motor_coords))]\n            z = np.clip(zc - patch_size[0]//2 + np.random.randint(-32, 32), 0, shape[0] - patch_size[0])\n            y = np.clip(yc - patch_size[1]//2 + np.random.randint(-32, 32), 0, shape[1] - patch_size[1])\n            x = np.clip(xc - patch_size[2]//2 + np.random.randint(-32, 32), 0, shape[2] - patch_size[2])\n        else:\n            z = np.random.randint(0, max(1, shape[0] - patch_size[0]))\n            y = np.random.randint(0, max(1, shape[1] - patch_size[1]))\n            x = np.random.randint(0, max(1, shape[2] - patch_size[2]))\n        patch = volume[z:z+patch_size[0], y:y+patch_size[1], x:x+patch_size[2]][np.newaxis, ...]\n        mask_patch = mask[z:z+patch_size[0], y:y+patch_size[1], x:x+patch_size[2]][np.newaxis, ...]\n        patches.append(patch)\n        mask_patches.append(mask_patch)\n    \n    for _ in range(patches_per_volume // 2):\n        z = np.random.randint(0, max(1, shape[0] - patch_size[0]))\n        y = np.random.randint(0, max(1, shape[1] - patch_size[1]))\n        x = np.random.randint(0, max(1, shape[2] - patch_size[2]))\n        patch = volume[z:z+patch_size[0], y:y+patch_size[1], x:x+patch_size[2]][np.newaxis, ...]\n        mask_patch = mask[z:z+patch_size[0], y:y+patch_size[1], x:x+patch_size[2]][np.newaxis, ...]\n        patches.append(patch)\n        mask_patches.append(mask_patch)\n    \n    return np.array(patches), np.array(mask_patches)\n\n# Patch dataset\nclass PatchDataset(Dataset):\n    def __init__(self, patches, mask_patches):\n        self.patches = patches\n        self.mask_patches = mask_patches\n    \n    def __len__(self):\n        return len(self.patches)\n    \n    def __getitem__(self, idx):\n        patch = self.patches[idx]\n        mask_patch = self.mask_patches[idx]\n        return torch.tensor(patch, dtype=torch.float32), torch.tensor(mask_patch, dtype=torch.float32)\n\n# Tomogram dataset\nclass TomogramDataset(Dataset):\n    def __init__(self, tomo_id, gcs_preprocessed_path, local_dir, mode=\"test\"):\n        self.tomo_id = tomo_id\n        self.gcs_preprocessed_path = gcs_preprocessed_path\n        self.gcs_precomputed_path = gcs_preprocessed_path.replace(\"preprocessed\", \"precomputedmasks\")\n        self.local_dir = local_dir\n        self.mode = mode\n        self.volume = None\n    \n    def load(self):\n        tomo_path, mask_path = download_npy_and_mask(\n            self.tomo_id, \n            self.gcs_preprocessed_path, \n            self.gcs_precomputed_path, \n            \"train\" if self.mode == \"val\" else self.mode, \n            self.local_dir\n        )\n        self.volume = np.load(tomo_path)\n        print(f\"Loaded tomogram {self.tomo_id} (shape: {self.volume.shape})\", flush=True)\n        logger.info(f\"Loaded tomogram {self.tomo_id} (shape: {self.volume.shape})\")\n        if os.path.exists(mask_path):\n            self.mask = np.load(mask_path)\n            print(f\"Loaded mask {self.tomo_id} (min/max: {self.mask.min()}/{self.mask.max()})\", flush=True)\n            logger.info(f\"Loaded mask {self.tomo_id} (min/max: {self.mask.min()}/{self.mask.max()})\")\n        else: \n            self.mask = np.zeros_like(self.volume)\n            print(f\"No mask found for {self.tomo_id}, using zeros (shape: {self.mask.shape})\", flush=True)\n            logger.info(f\"No mask found for {self.tomo_id}, using zeros (shape: {self.mask.shape})\")\n\n    \n    def clear(self):\n        tomo_path = os.path.join(self.local_dir, f\"{self.tomo_id}.npy\")\n        mask_path = os.path.join(self.local_dir, f\"{self.tomo_id}_mask.npy\")\n        for path in [tomo_path, mask_path]:\n            if os.path.exists(path):\n                os.remove(path)\n                logger.info(f\"Deleted {path}, disk: {os.popen('df -h /kaggle/working').read()}\")\n        if self.volume is not None:\n            del self.volume\n            self.volume = None\n        if self.mask is not None:\n            del self.mask\n            self.mask = None\n        gc.collect()\n    \n    def __len__(self):\n        return 1\n    \n    def __getitem__(self, idx):\n        if self.volume is None:\n            self.load()\n        volume = torch.from_numpy(self.volume).float()\n        if len(volume.shape) == 3:  # (z, y, x) -> (1, 1, z, y, x)\n            volume = volume.unsqueeze(0).unsqueeze(0)\n        elif len(volume.shape) != 5:\n            raise ValueError(f\"Unexpected volume shape: {volume.shape}\")\n        mask = torch.from_numpy(self.mask).float() if self.mask is not None else torch.zeros_like(volume)\n        if len(mask.shape) == 3:\n            mask = mask.unsqueeze(0).unsqueeze(0)\n        elif len(mask.shape) != 5 and self.mask is not None:\n            raise ValueError(f\"Unexpected mask shape: {mask.shape}\")\n        return volume, mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:08:50.602368Z","iopub.execute_input":"2025-05-22T02:08:50.602994Z","iopub.status.idle":"2025-05-22T02:08:50.620295Z","shell.execute_reply.started":"2025-05-22T02:08:50.602968Z","shell.execute_reply":"2025-05-22T02:08:50.61966Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Initialize model\nmodel = UNet(\n    spatial_dims=3,\n    in_channels=1,\n    out_channels=1,\n    channels=(16, 32, 64, 128, 256),\n    strides=(2, 2, 2, 2),\n    num_res_units=2,\n)\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs with DataParallel\", flush=True)\n    model = torch.nn.DataParallel(model)\nmodel = model.to(device)\nlogger.info(f\"Model device: {next(model.parameters()).device}\")\n\n# Loss and optimizer\ncriterion = DiceLoss(sigmoid=True)\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.1, patience=5)\n\n# Load checkpoint if available\nstart_epoch = 0\nbest_val_loss = float(\"inf\")\ntrain_losses = []\nval_losses = []\nif os.path.exists(\"checkpoint.pth\"):\n    checkpoint = torch.load(\"checkpoint.pth\", map_location=device)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n    best_val_loss = checkpoint['best_val_loss']\n    start_epoch = checkpoint['epoch'] + 1\n    logger.info(f\"Resumed from epoch {start_epoch}\")\nelse:\n    logger.info(\"No checkpoint found, starting from scratch.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:08:57.000366Z","iopub.execute_input":"2025-05-22T02:08:57.001101Z","iopub.status.idle":"2025-05-22T02:08:57.250356Z","shell.execute_reply.started":"2025-05-22T02:08:57.001073Z","shell.execute_reply":"2025-05-22T02:08:57.249554Z"}},"outputs":[{"name":"stdout","text":"Using 2 GPUs with DataParallel\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# TRAINING FUNCTION LOOP \n","metadata":{}},{"cell_type":"code","source":"# Training function\n# Training function with print-based logging\ndef train_epoch(model, loader, criterion, optimizer, epoch, start_epoch, tomo_id):\n    model.train()\n    epoch_loss = 0.0\n    start = time.time()\n    for i, (inputs, targets) in enumerate(tqdm(loader, desc=f\"Training tomo {tomo_id}\", file=sys.stdout, disable=True)):\n        batch_load_time = time.time() - start\n        inputs = inputs.to(device)\n        targets = targets.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n        # Print batch progress to console\n        print(f\"Epoch {epoch+1}, Tomo {tomo_id}, Batch {i+1}/{len(loader)}, Loss: {loss.item():.4f}\", flush=True)\n        # Detailed logs for first 2 batches of first epoch (to console and file)\n        if epoch == start_epoch and i < 2:\n            # print(f\"Tomo {tomo_id}, Batch {i} load time: {batch_load_time:.2f}s\", flush=True)\n            # print(f\"Inputs shape: {inputs.shape}, min/max: {inputs.min().item():.4f}/{inputs.max().item():.4f}\", flush=True)\n            # print(f\"Targets shape: {targets.shape}, min/max: {targets.min().item():.4f}/{targets.max().item():.4f}\", flush=True)\n            # print(f\"Outputs shape: {outputs.shape}, min/max: {outputs.min().item():.4f}/{outputs.max().item():.4f}\", flush=True)\n            # print(f\"Loss: {loss.item():.4f}\", flush=True)\n            # print(f\"GPU Memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\", flush=True)\n            logger.info(f\"Tomo {tomo_id}, Batch {i} load time: {batch_load_time:.2f}s\")\n            logger.info(f\"Inputs shape: {inputs.shape}, min/max: {inputs.min().item():.4f}/{inputs.max().item():.4f}\")\n            logger.info(f\"Targets shape: {targets.shape}, min/max: {targets.min().item():.4f}/{targets.max().item():.4f}\")\n            logger.info(f\"Outputs shape: {outputs.shape}, min/max: {outputs.min().item():.4f}/{outputs.max().item():.4f}\")\n            logger.info(f\"Loss: {loss.item():.4f}\")\n            logger.info(f\"GPU Memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n            torch.cuda.synchronize()\n            logger.info(torch.cuda.memory_summary())\n        sys.stdout.flush()\n        start = time.time() \n    avg_loss = epoch_loss / len(loader)\n    print(f\"Epoch {epoch+1}, Tomo {tomo_id} completed, Average Loss: {avg_loss:.4f}\", flush=True)\n    sys.stdout.flush()\n    return avg_loss\n\n# Cache validation tomograms\ndef cache_validation_tomograms(val_ids, gcs_preprocessed_path, gcs_precomputed_path, local_dir):\n    selected_val_ids = [tid for tid in val_ids if tid == \"tomo_ab804d\"] + [tid for tid in val_ids if tid != \"tomo_ab804d\"][:4]\n    for tomo_id in selected_val_ids:\n        tomo_path, mask_path = download_npy_and_mask(tomo_id, gcs_preprocessed_path, gcs_precomputed_path, \"train\", local_dir)\n        logger.info(f\"Cached {tomo_id} at {tomo_path}, {mask_path}\")\n    return selected_val_ids\n\n# Parallel data loading for validation\ndef load_tomogram_for_validation(tomo_id, gcs_preprocessed_path, gcs_precomputed_path, local_dir, labels_df, patches_per_volume):\n    try:\n        tomo_path = os.path.join(local_dir, f\"{tomo_id}.npy\")\n        mask_path = os.path.join(local_dir, f\"{tomo_id}_mask.npy\")\n        if not (os.path.exists(tomo_path) and os.path.exists(mask_path)):\n            tomo_path, mask_path = download_npy_and_mask(tomo_id, gcs_preprocessed_path, gcs_precomputed_path, \"train\", local_dir)\n        volume = np.load(tomo_path)\n        mask = np.load(mask_path)\n        patches, mask_patches = sample_patches(tomo_id, volume, mask, labels_df, patches_per_volume=patches_per_volume)\n        return tomo_id, patches, mask_patches, [tomo_path, mask_path]\n    except Exception as e:\n        logger.error(f\"Error loading tomogram {tomo_id}: {str(e)}\")\n        raise\n\n# Optimized validate function\ndef validate(model, val_ids, gcs_preprocessed_path, gcs_precomputed_path, local_dir, labels_df, criterion, patch_size):\n    model.eval()\n    epoch_loss = 0.0\n    patches_per_volume = 8\n    selected_val_ids = cache_validation_tomograms(val_ids, gcs_preprocessed_path, gcs_precomputed_path, local_dir)\n    with ThreadPoolExecutor(max_workers=4) as executor:\n        future_to_tomo = {\n            executor.submit(\n                load_tomogram_for_validation,\n                tomo_id,\n                gcs_preprocessed_path,\n                gcs_precomputed_path,\n                local_dir,\n                labels_df,\n                patches_per_volume\n            ): tomo_id for tomo_id in selected_val_ids\n        }\n        for future in tqdm(as_completed(future_to_tomo), total=len(selected_val_ids), desc=\"Validation\"):\n            tomo_id = future_to_tomo[future]\n            logger.warning(f\"Validating tomogram {tomo_id}\")\n            try:\n                tomo_id, patches, mask_patches, paths = future.result()\n                tomo_labels = labels_df[labels_df[\"tomo_id\"] == tomo_id].iloc[0]\n                num_motors = tomo_labels[\"Number of motors\"]\n                log_info(f\"Tomogram {tomo_id} has {num_motors} motors\")\n                \n                dataset = PatchDataset(patches, mask_patches)\n                loader = DataLoader(dataset, batch_size=8, shuffle=False, num_workers=2, pin_memory=True)\n                \n                with torch.no_grad():\n                    for i, (inputs, targets) in enumerate(loader):\n                        inputs = inputs.to(device)\n                        targets = targets.to(device)\n                        outputs = model(inputs)\n                        loss = criterion(outputs, targets)\n                        epoch_loss += loss.item()\n                        log_info(f\"Validation tomo {tomo_id}, Batch {i+1}, Loss: {loss.item():.4f}\")\n                \n                if tomo_id == \"tomo_ab804d\":\n                    mask_path = os.path.join(local_dir, f\"{tomo_id}_mask.npy\")\n                    gt_mask = np.load(mask_path)\n                    tomo_path = os.path.join(local_dir, f\"{tomo_id}.npy\")\n                    volume = np.load(tomo_path)\n                    slice_idx = volume.shape[0] // 2\n                    tomo_slice = volume[slice_idx, :, :]\n                    pred_patch = outputs[0, 0, patch_size[0]//2, :, :].cpu().numpy()\n                    gt_patch = targets[0, 0, patch_size[0]//2, :, :].cpu().numpy()\n                    gt_row = labels_df[labels_df[\"tomo_id\"] == tomo_id].iloc[0]\n                    gt_z, gt_y, gt_x = gt_row[\"Motor axis 0\"], gt_row[\"Motor axis 1\"], gt_row[\"Motor axis 2\"]\n\n                    plt.figure(figsize=(15, 5))\n                    plt.subplot(1, 3, 1)\n                    plt.imshow(tomo_slice, cmap=\"gray\")\n                    plt.title(f\"Tomogram Slice (z={slice_idx})\")\n                    plt.axis(\"off\")\n                    plt.subplot(1, 3, 2)\n                    plt.imshow(pred_patch, cmap=\"hot\")\n                    plt.title(\"Predicted Patch\")\n                    plt.axis(\"off\")\n                    plt.subplot(1, 3, 3)\n                    plt.imshow(gt_patch, cmap=\"hot\")\n                    if gt_z != -1:\n                        plt.scatter(gt_x % patch_size[2], gt_y % patch_size[1], c=\"green\", marker=\"o\", s=100, label=\"Ground Truth\")\n                        plt.legend()\n                    plt.title(\"Ground Truth Patch\")\n                    plt.axis(\"off\")\n                    plt.tight_layout()\n                    plt.savefig(f\"/kaggle/working/viz_{tomo_id}_patch.png\")\n                    plt.close()\n                    logger.warning(f\"Saved visualization for {tomo_id}\")\n\n                del dataset, loader, patches, mask_patches\n                clean_memory([tomo_id], local_dir)\n            except Exception as e:\n                logger.error(f\"Error validating tomogram {tomo_id}: {str(e)}\")\n                raise\n    return epoch_loss / (len(selected_val_ids) * patches_per_volume)\n\n\n# Clean memory after processing tomograms\ndef clean_memory(tomo_ids, local_dir):\n    \"\"\"Delete tomogram and mask files and clear GPU memory.\"\"\"\n    for tomo_id in tomo_ids:\n        tomo_path = os.path.join(local_dir, f\"{tomo_id}.npy\")\n        mask_path = os.path.join(local_dir, f\"{tomo_id}_mask.npy\")\n        for path in [tomo_path, mask_path]:\n            if os.path.exists(path):\n                os.remove(path)\n                logger.info(f\"Deleted {path}\")\n    gc.collect()\n    torch.cuda.empty_cache()\n    logger.info(\"Cleared memory and GPU cache\")\n\n\n# Prefetch thread for producer-consumer queue\ndata_queue = queue.Queue(maxsize=2)\ndef prefetch_batches(train_ids, batch_size, gcs_preprocessed_path, gcs_precomputed_path, local_dir, labels_df, patches_per_volume):\n    for batch_start in range(0, len(train_ids), batch_size):\n        batch_tomo_ids = train_ids[batch_start:batch_start + batch_size]\n        logger.warning(f\"Prefetching batch of tomograms: {batch_tomo_ids}\")\n        batch_data = []\n        download_start_time = time.time()\n        try:\n            with ThreadPoolExecutor(max_workers=batch_size) as executor:\n                future_to_tomo = {\n                    executor.submit(\n                        download_and_preprocess,\n                        tomo_id,\n                        gcs_preprocessed_path,\n                        gcs_precomputed_path,\n                        \"train\",\n                        local_dir,\n                        labels_df,\n                        patches_per_volume\n                    ): tomo_id for tomo_id in batch_tomo_ids\n                }\n                for future in as_completed(future_to_tomo):\n                    batch_data.append(future.result())\n            logger.warning(f\"Batch prefetch time for {batch_tomo_ids}: {time.time() - download_start_time:.2f} seconds\")\n            data_queue.put((batch_tomo_ids, batch_data))\n        except Exception as e:\n            logger.error(f\"Error prefetching batch {batch_tomo_ids}: {str(e)}\")\n            raise\n\n\n# Training loop with batch processing\nnum_epochs = 2\npatience = 10\ntrigger_times = 0\npatches_per_volume_train = 64\nbatch_size = 4  # Process 5 tomograms at a time\nmetrics_log = []  # Store metrics for concise reporting\nbest_val_loss = float(\"inf\")\ntrain_losses = []\nval_losses = []\nfirst_epoch = True\n\n# Analyze and plot tomogram distribution\ntotal_tomograms, motor_tomograms, non_motor_tomograms = analyze_tomograms(labels_df)\nplot_tomogram_distribution(labels_df)\n\n\nfor epoch in range(start_epoch, num_epochs):\n    logger.info(f\"STARTING TRAINING - Epoch {epoch+1}/{num_epochs}\")\n    print(f\"STARTING TRAINING - Epoch {epoch+1}/{num_epochs}\", flush=True)  \n    sys.stdout.flush()\n    epoch_train_loss = 0.0\n    processed_tomograms = 0\n    #total_train_tomograms = len(train_ids)\n    total_train_tomograms = min(8, len(train_ids))  # Limit to 8 tomograms (2 batches)\n\n    # Start prefetch thread\n    prefetch_thread = threading.Thread(\n        target=prefetch_batches,\n        #args=(train_ids, batch_size, gcs_preprocessed_path, gcs_precomputed_path, local_dir, labels_df, patches_per_volume_train)\n        args=(train_ids[:8], batch_size, gcs_preprocessed_path, gcs_precomputed_path, local_dir, labels_df, patches_per_volume_train)\n    )\n    prefetch_thread.start()\n\n\n    # Process tomograms in batches\n    #for batch_start in range(0, len(train_ids), batch_size):\n    for batch_start in range(0, min(8, len(train_ids)), batch_size):\n        batch_tomo_ids, batch_data = data_queue.get()\n        logger.warning(f\"Processing batch of tomograms: {batch_tomo_ids}\")\n        print(f\"Processing batch of tomograms: {batch_tomo_ids}\", flush=True)\n        sys.stdout.flush()\n\n        # Train on batch\n        for tomo_id, patches, mask_patches in batch_data:\n            try:\n                dataset = PatchDataset(patches, mask_patches)\n                loader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=2, pin_memory=True)\n                logger.warning(f\"Training on tomogram {tomo_id}\")\n                print(f\"Training on tomogram {tomo_id}\", flush=True)\n                batch_loss = train_epoch(model, loader, criterion, optimizer, epoch, start_epoch, tomo_id)\n                epoch_train_loss += batch_loss\n                processed_tomograms += 1\n                logger.warning(f\"Completed training on tomogram {tomo_id}, Loss: {batch_loss:.4f}\")\n                print(f\"Completed training on tomogram {tomo_id}, Loss: {batch_loss:.4f}\", flush=True)\n                print(f\"Processed {processed_tomograms}/{total_train_tomograms} tomograms\", flush=True)\n                logger.warning(f\"Processed {processed_tomograms}/{total_train_tomograms} tomograms\")\n                del dataset, loader, patches, mask_patches\n            except Exception as e:\n                logger.error(f\"Error training tomogram {tomo_id}: {str(e)}\")\n                raise\n            sys.stdout.flush()\n\n        # Clean up\n        print(f\"Cleaning memory for batch: {batch_tomo_ids}\", flush=True)\n        logger.info(f\"Cleaning memory for batch: {batch_tomo_ids}\")\n        clean_memory(batch_tomo_ids, local_dir)\n\n    prefetch_thread.join()  # Wait for prefetching to complete\n\n    train_loss = epoch_train_loss / max(1, processed_tomograms)\n    train_losses.append(train_loss)\n\n    # Validation\n    logger.info(\"Starting validation\")\n    patch_size = (128, 128, 128)  # Match sample_patches\n    val_loss = validate(model, val_ids, gcs_preprocessed_path, gcs_precomputed_path, local_dir, labels_df, criterion, patch_size)\n    val_losses.append(val_loss)\n    \n    # Log metrics\n    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\", flush=True)\n    logger.info(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n    #wandb.log({\n    #    \"epoch\": epoch + 1,\n    #    \"train_loss\": train_loss,\n    #    \"val_loss\": val_loss,\n    #    \"learning_rate\": optimizer.param_groups[0][\"lr\"]\n    #})\n    metrics_log.append({\n        \"epoch\": epoch + 1,\n        \"train_loss\": train_loss,\n        \"val_loss\": val_loss\n    })\n    \n    # Save metrics to file\n    pd.DataFrame(metrics_log).to_csv(\"/kaggle/working/training_metrics.csv\", index=False)\n    print(\"TEMP Saved training metrics to training_metrics.csv\")\n    logger.info(\"Saved training metrics to training_metrics.csv\")\n    sys.stdout.flush()\n\n    scheduler.step(val_loss)   # Learning rate scheduling\n\n    # GPU diagnostics every 10 epochs\n    if (epoch + 1) % 10 == 0:\n        torch.cuda.synchronize()\n        logger.info(f\"GPU Memory after Epoch {epoch+1}:\\n{torch.cuda.memory_summary()}\")\n        nvidia_smi_output = os.popen(\"nvidia-smi\").read()\n        logger.info(f\"nvidia-smi output after Epoch {epoch+1}:\\n{nvidia_smi_output}\")\n        sys.stdout.flush()\n\n    \n    # Checkpointing and Early stopping\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        trigger_times = 0\n        torch.save({               # Save full training state \n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'scheduler_state_dict': scheduler.state_dict(),\n            'best_val_loss': best_val_loss\n        }, \"checkpoint.pth\")\n        torch.save(model.state_dict(), \"/kaggle/working/best_model.pth\") #Save model weights for inference / tuning \n        print(\"Saved checkpoint and best model\", flush=True)\n        logger.info(\"Saved checkpoint and best model\")\n        # Log the best model to wandb - Uncomment the below. \n        #artifact = wandb.Artifact(\"best_model\", type=\"model\")\n        #artifact.add_file(\"best_model.pth\")\n        #wandb.log_artifact(artifact)\n    else:\n        trigger_times += 1\n        if trigger_times >= patience:\n            print(\"Early stopping triggered!\", flush=True)\n            logger.info(\"Early stopping triggered!\")\n            break\n\n    # Flush logs to ensure training.log is updated\n    file_handler.flush()\n    file_handler.stream.flush()\n\n# Plot losses\nplt.figure(figsize=(10, 5))\nplt.plot(train_losses, label=\"Training Loss\")\nplt.plot(val_losses, label=\"Validation Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training and Validation Loss Over Epochs\")\nplt.legend()\nplt.grid(True)\nplt.savefig(\"loss_plot.png\")\nplt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T02:30:06.554744Z","iopub.execute_input":"2025-05-22T02:30:06.555084Z","iopub.status.idle":"2025-05-22T02:47:25.647663Z","shell.execute_reply.started":"2025-05-22T02:30:06.555057Z","shell.execute_reply":"2025-05-22T02:47:25.646823Z"}},"outputs":[{"name":"stdout","text":"Total tomograms: 648\nTomograms with motors: 451\nTomograms without motors: 197\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x500 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"STARTING TRAINING - Epoch 1/2\nWARNING - Prefetching batch of tomograms: ['tomo_3c6038', 'tomo_369cce', 'tomo_cff77a', 'tomo_60d478']\nWARNING - Completed parallel download for tomogram tomo_60d478\nWARNING - Completed parallel download for tomogram tomo_3c6038\nWARNING - Completed parallel download for tomogram tomo_369cce\nWARNING - Completed parallel download for tomogram tomo_cff77a\nWARNING - Prepared patches for tomogram tomo_60d478\nWARNING - Prepared patches for tomogram tomo_cff77a\nWARNING - Prepared patches for tomogram tomo_3c6038\nWARNING - Prepared patches for tomogram tomo_369cce\nWARNING - Batch prefetch time for ['tomo_3c6038', 'tomo_369cce', 'tomo_cff77a', 'tomo_60d478']: 64.06 seconds\nWARNING - Prefetching batch of tomograms: ['tomo_1c38fd', 'tomo_98d455', 'tomo_4e38b8', 'tomo_b7d014']\nWARNING - Processing batch of tomograms: ['tomo_3c6038', 'tomo_369cce', 'tomo_cff77a', 'tomo_60d478']\nProcessing batch of tomograms: ['tomo_3c6038', 'tomo_369cce', 'tomo_cff77a', 'tomo_60d478']\nWARNING - Training on tomogram tomo_60d478\nTraining on tomogram tomo_60d478\nEpoch 1, Tomo tomo_60d478, Batch 1/16, Loss: 0.9987\nEpoch 1, Tomo tomo_60d478, Batch 2/16, Loss: 0.9983\nEpoch 1, Tomo tomo_60d478, Batch 3/16, Loss: 0.9991\nEpoch 1, Tomo tomo_60d478, Batch 4/16, Loss: 0.9972\nEpoch 1, Tomo tomo_60d478, Batch 5/16, Loss: 0.9982\nEpoch 1, Tomo tomo_60d478, Batch 6/16, Loss: 0.9964\nEpoch 1, Tomo tomo_60d478, Batch 7/16, Loss: 0.9972\nEpoch 1, Tomo tomo_60d478, Batch 8/16, Loss: 0.9972\nEpoch 1, Tomo tomo_60d478, Batch 9/16, Loss: 0.9972\nEpoch 1, Tomo tomo_60d478, Batch 10/16, Loss: 0.9963\nEpoch 1, Tomo tomo_60d478, Batch 11/16, Loss: 0.9991\nEpoch 1, Tomo tomo_60d478, Batch 12/16, Loss: 1.0000\nEpoch 1, Tomo tomo_60d478, Batch 13/16, Loss: 0.9980\nEpoch 1, Tomo tomo_60d478, Batch 14/16, Loss: 1.0000\nEpoch 1, Tomo tomo_60d478, Batch 15/16, Loss: 1.0000\nEpoch 1, Tomo tomo_60d478, Batch 16/16, Loss: 0.9980\nEpoch 1, Tomo tomo_60d478 completed, Average Loss: 0.9982\nWARNING - Completed training on tomogram tomo_60d478, Loss: 0.9982\nCompleted training on tomogram tomo_60d478, Loss: 0.9982\nProcessed 1/8 tomograms\nWARNING - Processed 1/8 tomograms\nWARNING - Training on tomogram tomo_cff77a\nTraining on tomogram tomo_cff77a\nEpoch 1, Tomo tomo_cff77a, Batch 1/16, Loss: 0.9980\nEpoch 1, Tomo tomo_cff77a, Batch 2/16, Loss: 0.9969\nEpoch 1, Tomo tomo_cff77a, Batch 3/16, Loss: 0.9980\nEpoch 1, Tomo tomo_cff77a, Batch 4/16, Loss: 0.9969\nEpoch 1, Tomo tomo_cff77a, Batch 5/16, Loss: 0.9969\nEpoch 1, Tomo tomo_cff77a, Batch 6/16, Loss: 0.9977\nEpoch 1, Tomo tomo_cff77a, Batch 7/16, Loss: 0.9989\nEpoch 1, Tomo tomo_cff77a, Batch 8/16, Loss: 1.0000\nEpoch 1, Tomo tomo_cff77a, Batch 9/16, Loss: 0.9969\nEpoch 1, Tomo tomo_cff77a, Batch 10/16, Loss: 0.9979\nEpoch 1, Tomo tomo_cff77a, Batch 11/16, Loss: 0.9968\nEpoch 1, Tomo tomo_cff77a, Batch 12/16, Loss: 0.9981\nEpoch 1, Tomo tomo_cff77a, Batch 13/16, Loss: 0.9989\nEpoch 1, Tomo tomo_cff77a, Batch 14/16, Loss: 0.9980\nEpoch 1, Tomo tomo_cff77a, Batch 15/16, Loss: 0.9990\nEpoch 1, Tomo tomo_cff77a, Batch 16/16, Loss: 0.9979\nEpoch 1, Tomo tomo_cff77a completed, Average Loss: 0.9979\nWARNING - Completed training on tomogram tomo_cff77a, Loss: 0.9979\nCompleted training on tomogram tomo_cff77a, Loss: 0.9979\nProcessed 2/8 tomograms\nWARNING - Processed 2/8 tomograms\nWARNING - Training on tomogram tomo_3c6038\nTraining on tomogram tomo_3c6038\nEpoch 1, Tomo tomo_3c6038, Batch 1/16, Loss: 0.9968\nEpoch 1, Tomo tomo_3c6038, Batch 2/16, Loss: 0.9989\nEpoch 1, Tomo tomo_3c6038, Batch 3/16, Loss: 0.9990\nEpoch 1, Tomo tomo_3c6038, Batch 4/16, Loss: 0.9979\nEpoch 1, Tomo tomo_3c6038, Batch 5/16, Loss: 0.9978\nEpoch 1, Tomo tomo_3c6038, Batch 6/16, Loss: 0.9968\nEpoch 1, Tomo tomo_3c6038, Batch 7/16, Loss: 0.9978\nEpoch 1, Tomo tomo_3c6038, Batch 8/16, Loss: 0.9978\nEpoch 1, Tomo tomo_3c6038, Batch 9/16, Loss: 0.9989\nEpoch 1, Tomo tomo_3c6038, Batch 10/16, Loss: 0.9968\nEpoch 1, Tomo tomo_3c6038, Batch 11/16, Loss: 0.9968\nEpoch 1, Tomo tomo_3c6038, Batch 12/16, Loss: 0.9978\nEpoch 1, Tomo tomo_3c6038, Batch 13/16, Loss: 0.9978\nEpoch 1, Tomo tomo_3c6038, Batch 14/16, Loss: 0.9978\nEpoch 1, Tomo tomo_3c6038, Batch 15/16, Loss: 0.9978\nEpoch 1, Tomo tomo_3c6038, Batch 16/16, Loss: 0.9989\nEpoch 1, Tomo tomo_3c6038 completed, Average Loss: 0.9978\nWARNING - Completed training on tomogram tomo_3c6038, Loss: 0.9978\nCompleted training on tomogram tomo_3c6038, Loss: 0.9978\nProcessed 3/8 tomograms\nWARNING - Processed 3/8 tomograms\nWARNING - Training on tomogram tomo_369cce\nTraining on tomogram tomo_369cce\nEpoch 1, Tomo tomo_369cce, Batch 1/16, Loss: 0.9989\nEpoch 1, Tomo tomo_369cce, Batch 2/16, Loss: 0.9968\nEpoch 1, Tomo tomo_369cce, Batch 3/16, Loss: 0.9989\nEpoch 1, Tomo tomo_369cce, Batch 4/16, Loss: 0.9989\nEpoch 1, Tomo tomo_369cce, Batch 5/16, Loss: 0.9966\nEpoch 1, Tomo tomo_369cce, Batch 6/16, Loss: 0.9977\nEpoch 1, Tomo tomo_369cce, Batch 7/16, Loss: 0.9989\nEpoch 1, Tomo tomo_369cce, Batch 8/16, Loss: 0.9966\nEpoch 1, Tomo tomo_369cce, Batch 9/16, Loss: 0.9989\nEpoch 1, Tomo tomo_369cce, Batch 10/16, Loss: 0.9965\nEpoch 1, Tomo tomo_369cce, Batch 11/16, Loss: 0.9977\nEpoch 1, Tomo tomo_369cce, Batch 12/16, Loss: 0.9977\nEpoch 1, Tomo tomo_369cce, Batch 13/16, Loss: 0.9965\nEpoch 1, Tomo tomo_369cce, Batch 14/16, Loss: 0.9976\nEpoch 1, Tomo tomo_369cce, Batch 15/16, Loss: 0.9976\nEpoch 1, Tomo tomo_369cce, Batch 16/16, Loss: 0.9976\nEpoch 1, Tomo tomo_369cce completed, Average Loss: 0.9977\nWARNING - Completed training on tomogram tomo_369cce, Loss: 0.9977\nCompleted training on tomogram tomo_369cce, Loss: 0.9977\nProcessed 4/8 tomograms\nWARNING - Processed 4/8 tomograms\nCleaning memory for batch: ['tomo_3c6038', 'tomo_369cce', 'tomo_cff77a', 'tomo_60d478']\nWARNING - Completed parallel download for tomogram tomo_1c38fd\nWARNING - Completed parallel download for tomogram tomo_4e38b8\nWARNING - Completed parallel download for tomogram tomo_98d455\nWARNING - Prepared patches for tomogram tomo_1c38fd\nWARNING - Prepared patches for tomogram tomo_4e38b8\nWARNING - Prepared patches for tomogram tomo_98d455\nWARNING - Completed parallel download for tomogram tomo_b7d014\nWARNING - Prepared patches for tomogram tomo_b7d014\nWARNING - Batch prefetch time for ['tomo_1c38fd', 'tomo_98d455', 'tomo_4e38b8', 'tomo_b7d014']: 81.97 seconds\nWARNING - Processing batch of tomograms: ['tomo_1c38fd', 'tomo_98d455', 'tomo_4e38b8', 'tomo_b7d014']\nProcessing batch of tomograms: ['tomo_1c38fd', 'tomo_98d455', 'tomo_4e38b8', 'tomo_b7d014']\nWARNING - Training on tomogram tomo_1c38fd\nTraining on tomogram tomo_1c38fd\nEpoch 1, Tomo tomo_1c38fd, Batch 1/16, Loss: 0.9965\nEpoch 1, Tomo tomo_1c38fd, Batch 2/16, Loss: 1.0000\nEpoch 1, Tomo tomo_1c38fd, Batch 3/16, Loss: 0.9965\nEpoch 1, Tomo tomo_1c38fd, Batch 4/16, Loss: 0.9976\nEpoch 1, Tomo tomo_1c38fd, Batch 5/16, Loss: 0.9975\nEpoch 1, Tomo tomo_1c38fd, Batch 6/16, Loss: 0.9963\nEpoch 1, Tomo tomo_1c38fd, Batch 7/16, Loss: 0.9975\nEpoch 1, Tomo tomo_1c38fd, Batch 8/16, Loss: 0.9972\nEpoch 1, Tomo tomo_1c38fd, Batch 9/16, Loss: 0.9986\nEpoch 1, Tomo tomo_1c38fd, Batch 10/16, Loss: 0.9975\nEpoch 1, Tomo tomo_1c38fd, Batch 11/16, Loss: 0.9987\nEpoch 1, Tomo tomo_1c38fd, Batch 12/16, Loss: 0.9987\nEpoch 1, Tomo tomo_1c38fd, Batch 13/16, Loss: 0.9975\nEpoch 1, Tomo tomo_1c38fd, Batch 14/16, Loss: 0.9962\nEpoch 1, Tomo tomo_1c38fd, Batch 15/16, Loss: 0.9962\nEpoch 1, Tomo tomo_1c38fd, Batch 16/16, Loss: 0.9974\nEpoch 1, Tomo tomo_1c38fd completed, Average Loss: 0.9975\nWARNING - Completed training on tomogram tomo_1c38fd, Loss: 0.9975\nCompleted training on tomogram tomo_1c38fd, Loss: 0.9975\nProcessed 5/8 tomograms\nWARNING - Processed 5/8 tomograms\nWARNING - Training on tomogram tomo_4e38b8\nTraining on tomogram tomo_4e38b8\nEpoch 1, Tomo tomo_4e38b8, Batch 1/16, Loss: 0.9974\nEpoch 1, Tomo tomo_4e38b8, Batch 2/16, Loss: 0.9987\nEpoch 1, Tomo tomo_4e38b8, Batch 3/16, Loss: 0.9961\nEpoch 1, Tomo tomo_4e38b8, Batch 4/16, Loss: 0.9960\nEpoch 1, Tomo tomo_4e38b8, Batch 5/16, Loss: 0.9973\nEpoch 1, Tomo tomo_4e38b8, Batch 6/16, Loss: 0.9987\nEpoch 1, Tomo tomo_4e38b8, Batch 7/16, Loss: 0.9973\nEpoch 1, Tomo tomo_4e38b8, Batch 8/16, Loss: 0.9959\nEpoch 1, Tomo tomo_4e38b8, Batch 9/16, Loss: 0.9973\nEpoch 1, Tomo tomo_4e38b8, Batch 10/16, Loss: 0.9973\nEpoch 1, Tomo tomo_4e38b8, Batch 11/16, Loss: 0.9973\nEpoch 1, Tomo tomo_4e38b8, Batch 12/16, Loss: 0.9986\nEpoch 1, Tomo tomo_4e38b8, Batch 13/16, Loss: 0.9958\nEpoch 1, Tomo tomo_4e38b8, Batch 14/16, Loss: 0.9986\nEpoch 1, Tomo tomo_4e38b8, Batch 15/16, Loss: 0.9972\nEpoch 1, Tomo tomo_4e38b8, Batch 16/16, Loss: 0.9972\nEpoch 1, Tomo tomo_4e38b8 completed, Average Loss: 0.9973\nWARNING - Completed training on tomogram tomo_4e38b8, Loss: 0.9973\nCompleted training on tomogram tomo_4e38b8, Loss: 0.9973\nProcessed 6/8 tomograms\nWARNING - Processed 6/8 tomograms\nWARNING - Training on tomogram tomo_98d455\nTraining on tomogram tomo_98d455\nEpoch 1, Tomo tomo_98d455, Batch 1/16, Loss: 0.9963\nEpoch 1, Tomo tomo_98d455, Batch 2/16, Loss: 0.9974\nEpoch 1, Tomo tomo_98d455, Batch 3/16, Loss: 0.9972\nEpoch 1, Tomo tomo_98d455, Batch 4/16, Loss: 0.9972\nEpoch 1, Tomo tomo_98d455, Batch 5/16, Loss: 0.9986\nEpoch 1, Tomo tomo_98d455, Batch 6/16, Loss: 0.9960\nEpoch 1, Tomo tomo_98d455, Batch 7/16, Loss: 0.9958\nEpoch 1, Tomo tomo_98d455, Batch 8/16, Loss: 0.9986\nEpoch 1, Tomo tomo_98d455, Batch 9/16, Loss: 0.9957\nEpoch 1, Tomo tomo_98d455, Batch 10/16, Loss: 0.9974\nEpoch 1, Tomo tomo_98d455, Batch 11/16, Loss: 0.9986\nEpoch 1, Tomo tomo_98d455, Batch 12/16, Loss: 1.0000\nEpoch 1, Tomo tomo_98d455, Batch 13/16, Loss: 0.9971\nEpoch 1, Tomo tomo_98d455, Batch 14/16, Loss: 0.9971\nEpoch 1, Tomo tomo_98d455, Batch 15/16, Loss: 0.9941\nEpoch 1, Tomo tomo_98d455, Batch 16/16, Loss: 0.9970\nEpoch 1, Tomo tomo_98d455 completed, Average Loss: 0.9971\nWARNING - Completed training on tomogram tomo_98d455, Loss: 0.9971\nCompleted training on tomogram tomo_98d455, Loss: 0.9971\nProcessed 7/8 tomograms\nWARNING - Processed 7/8 tomograms\nWARNING - Training on tomogram tomo_b7d014\nTraining on tomogram tomo_b7d014\nEpoch 1, Tomo tomo_b7d014, Batch 1/16, Loss: 0.9980\nEpoch 1, Tomo tomo_b7d014, Batch 2/16, Loss: 0.9960\nEpoch 1, Tomo tomo_b7d014, Batch 3/16, Loss: 0.9955\nEpoch 1, Tomo tomo_b7d014, Batch 4/16, Loss: 0.9970\nEpoch 1, Tomo tomo_b7d014, Batch 5/16, Loss: 0.9970\nEpoch 1, Tomo tomo_b7d014, Batch 6/16, Loss: 0.9969\nEpoch 1, Tomo tomo_b7d014, Batch 7/16, Loss: 0.9985\nEpoch 1, Tomo tomo_b7d014, Batch 8/16, Loss: 0.9969\nEpoch 1, Tomo tomo_b7d014, Batch 9/16, Loss: 0.9969\nEpoch 1, Tomo tomo_b7d014, Batch 10/16, Loss: 0.9969\nEpoch 1, Tomo tomo_b7d014, Batch 11/16, Loss: 0.9969\nEpoch 1, Tomo tomo_b7d014, Batch 12/16, Loss: 0.9974\nEpoch 1, Tomo tomo_b7d014, Batch 13/16, Loss: 0.9968\nEpoch 1, Tomo tomo_b7d014, Batch 14/16, Loss: 0.9984\nEpoch 1, Tomo tomo_b7d014, Batch 15/16, Loss: 0.9985\nEpoch 1, Tomo tomo_b7d014, Batch 16/16, Loss: 0.9965\nEpoch 1, Tomo tomo_b7d014 completed, Average Loss: 0.9971\nWARNING - Completed training on tomogram tomo_b7d014, Loss: 0.9971\nCompleted training on tomogram tomo_b7d014, Loss: 0.9971\nProcessed 8/8 tomograms\nWARNING - Processed 8/8 tomograms\nCleaning memory for batch: ['tomo_1c38fd', 'tomo_98d455', 'tomo_4e38b8', 'tomo_b7d014']\n","output_type":"stream"},{"name":"stderr","text":"Validation:   0%|          | 0/5 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"WARNING - Validating tomogram tomo_6303f0\n","output_type":"stream"},{"name":"stderr","text":"Validation:  20%|██        | 1/5 [00:08<00:32,  8.01s/it]","output_type":"stream"},{"name":"stdout","text":"WARNING - Validating tomogram tomo_e5a091\n","output_type":"stream"},{"name":"stderr","text":"Validation:  40%|████      | 2/5 [00:10<00:13,  4.59s/it]","output_type":"stream"},{"name":"stdout","text":"WARNING - Validating tomogram tomo_138018\n","output_type":"stream"},{"name":"stderr","text":"Validation:  60%|██████    | 3/5 [00:12<00:06,  3.35s/it]","output_type":"stream"},{"name":"stdout","text":"WARNING - Validating tomogram tomo_f427b3\n","output_type":"stream"},{"name":"stderr","text":"Validation:  80%|████████  | 4/5 [00:15<00:03,  3.38s/it]","output_type":"stream"},{"name":"stdout","text":"WARNING - Validating tomogram tomo_ab804d\nWARNING - Saved visualization for tomo_ab804d\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:47<00:00,  9.58s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 1/2, Train Loss: 0.9976, Val Loss: 0.1248\nTEMP Saved training metrics to training_metrics.csv\nSaved checkpoint and best model\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"STARTING TRAINING - Epoch 2/2\nWARNING - Prefetching batch of tomograms: ['tomo_3c6038', 'tomo_369cce', 'tomo_cff77a', 'tomo_60d478']\nWARNING - Completed parallel download for tomogram tomo_60d478\nWARNING - Completed parallel download for tomogram tomo_cff77a\nWARNING - Completed parallel download for tomogram tomo_3c6038\nWARNING - Completed parallel download for tomogram tomo_369cce\nWARNING - Prepared patches for tomogram tomo_60d478\nWARNING - Prepared patches for tomogram tomo_cff77a\nWARNING - Prepared patches for tomogram tomo_369cce\nWARNING - Prepared patches for tomogram tomo_3c6038\nWARNING - Batch prefetch time for ['tomo_3c6038', 'tomo_369cce', 'tomo_cff77a', 'tomo_60d478']: 67.81 seconds\nWARNING - Prefetching batch of tomograms: ['tomo_1c38fd', 'tomo_98d455', 'tomo_4e38b8', 'tomo_b7d014']\nWARNING - Processing batch of tomograms: ['tomo_3c6038', 'tomo_369cce', 'tomo_cff77a', 'tomo_60d478']\nProcessing batch of tomograms: ['tomo_3c6038', 'tomo_369cce', 'tomo_cff77a', 'tomo_60d478']\nWARNING - Training on tomogram tomo_60d478\nTraining on tomogram tomo_60d478\nEpoch 2, Tomo tomo_60d478, Batch 1/16, Loss: 1.0000\nEpoch 2, Tomo tomo_60d478, Batch 2/16, Loss: 0.9984\nEpoch 2, Tomo tomo_60d478, Batch 3/16, Loss: 0.9969\nEpoch 2, Tomo tomo_60d478, Batch 4/16, Loss: 0.9984\nEpoch 2, Tomo tomo_60d478, Batch 5/16, Loss: 0.9969\nEpoch 2, Tomo tomo_60d478, Batch 6/16, Loss: 0.9968\nEpoch 2, Tomo tomo_60d478, Batch 7/16, Loss: 0.9952\nEpoch 2, Tomo tomo_60d478, Batch 8/16, Loss: 0.9952\nEpoch 2, Tomo tomo_60d478, Batch 9/16, Loss: 0.9984\nEpoch 2, Tomo tomo_60d478, Batch 10/16, Loss: 0.9968\nEpoch 2, Tomo tomo_60d478, Batch 11/16, Loss: 0.9936\nEpoch 2, Tomo tomo_60d478, Batch 12/16, Loss: 0.9965\nEpoch 2, Tomo tomo_60d478, Batch 13/16, Loss: 0.9931\nEpoch 2, Tomo tomo_60d478, Batch 14/16, Loss: 0.9965\nEpoch 2, Tomo tomo_60d478, Batch 15/16, Loss: 0.9961\nEpoch 2, Tomo tomo_60d478, Batch 16/16, Loss: 0.9965\nEpoch 2, Tomo tomo_60d478 completed, Average Loss: 0.9966\nWARNING - Completed training on tomogram tomo_60d478, Loss: 0.9966\nCompleted training on tomogram tomo_60d478, Loss: 0.9966\nProcessed 1/8 tomograms\nWARNING - Processed 1/8 tomograms\nWARNING - Training on tomogram tomo_cff77a\nTraining on tomogram tomo_cff77a\nEpoch 2, Tomo tomo_cff77a, Batch 1/16, Loss: 1.0000\nEpoch 2, Tomo tomo_cff77a, Batch 2/16, Loss: 0.9928\nEpoch 2, Tomo tomo_cff77a, Batch 3/16, Loss: 0.9964\nEpoch 2, Tomo tomo_cff77a, Batch 4/16, Loss: 0.9964\nEpoch 2, Tomo tomo_cff77a, Batch 5/16, Loss: 0.9982\nEpoch 2, Tomo tomo_cff77a, Batch 6/16, Loss: 0.9967\nEpoch 2, Tomo tomo_cff77a, Batch 7/16, Loss: 0.9982\nEpoch 2, Tomo tomo_cff77a, Batch 8/16, Loss: 0.9973\nEpoch 2, Tomo tomo_cff77a, Batch 9/16, Loss: 0.9945\nEpoch 2, Tomo tomo_cff77a, Batch 10/16, Loss: 0.9964\nEpoch 2, Tomo tomo_cff77a, Batch 11/16, Loss: 0.9964\nEpoch 2, Tomo tomo_cff77a, Batch 12/16, Loss: 0.9981\nEpoch 2, Tomo tomo_cff77a, Batch 13/16, Loss: 0.9963\nEpoch 2, Tomo tomo_cff77a, Batch 14/16, Loss: 0.9981\nEpoch 2, Tomo tomo_cff77a, Batch 15/16, Loss: 0.9981\nEpoch 2, Tomo tomo_cff77a, Batch 16/16, Loss: 0.9923\nEpoch 2, Tomo tomo_cff77a completed, Average Loss: 0.9966\nWARNING - Completed training on tomogram tomo_cff77a, Loss: 0.9966\nCompleted training on tomogram tomo_cff77a, Loss: 0.9966\nProcessed 2/8 tomograms\nWARNING - Processed 2/8 tomograms\nWARNING - Training on tomogram tomo_369cce\nTraining on tomogram tomo_369cce\nEpoch 2, Tomo tomo_369cce, Batch 1/16, Loss: 0.9946\nEpoch 2, Tomo tomo_369cce, Batch 2/16, Loss: 0.9963\nEpoch 2, Tomo tomo_369cce, Batch 3/16, Loss: 0.9981\nEpoch 2, Tomo tomo_369cce, Batch 4/16, Loss: 1.0000\nEpoch 2, Tomo tomo_369cce, Batch 5/16, Loss: 0.9961\nEpoch 2, Tomo tomo_369cce, Batch 6/16, Loss: 0.9942\nEpoch 2, Tomo tomo_369cce, Batch 7/16, Loss: 0.9941\nEpoch 2, Tomo tomo_369cce, Batch 8/16, Loss: 0.9962\nEpoch 2, Tomo tomo_369cce, Batch 9/16, Loss: 0.9962\nEpoch 2, Tomo tomo_369cce, Batch 10/16, Loss: 0.9980\nEpoch 2, Tomo tomo_369cce, Batch 11/16, Loss: 0.9939\nEpoch 2, Tomo tomo_369cce, Batch 12/16, Loss: 0.9938\nEpoch 2, Tomo tomo_369cce, Batch 13/16, Loss: 0.9938\nEpoch 2, Tomo tomo_369cce, Batch 14/16, Loss: 0.9977\nEpoch 2, Tomo tomo_369cce, Batch 15/16, Loss: 0.9958\nEpoch 2, Tomo tomo_369cce, Batch 16/16, Loss: 0.9979\nEpoch 2, Tomo tomo_369cce completed, Average Loss: 0.9960\nWARNING - Completed training on tomogram tomo_369cce, Loss: 0.9960\nCompleted training on tomogram tomo_369cce, Loss: 0.9960\nProcessed 3/8 tomograms\nWARNING - Processed 3/8 tomograms\nWARNING - Training on tomogram tomo_3c6038\nTraining on tomogram tomo_3c6038\nEpoch 2, Tomo tomo_3c6038, Batch 1/16, Loss: 0.9958\nEpoch 2, Tomo tomo_3c6038, Batch 2/16, Loss: 0.9938\nEpoch 2, Tomo tomo_3c6038, Batch 3/16, Loss: 0.9979\nEpoch 2, Tomo tomo_3c6038, Batch 4/16, Loss: 0.9956\nEpoch 2, Tomo tomo_3c6038, Batch 5/16, Loss: 0.9935\nEpoch 2, Tomo tomo_3c6038, Batch 6/16, Loss: 0.9956\nEpoch 2, Tomo tomo_3c6038, Batch 7/16, Loss: 0.9956\nEpoch 2, Tomo tomo_3c6038, Batch 8/16, Loss: 0.9977\nEpoch 2, Tomo tomo_3c6038, Batch 9/16, Loss: 0.9936\nEpoch 2, Tomo tomo_3c6038, Batch 10/16, Loss: 0.9955\nEpoch 2, Tomo tomo_3c6038, Batch 11/16, Loss: 1.0000\nEpoch 2, Tomo tomo_3c6038, Batch 12/16, Loss: 1.0000\nEpoch 2, Tomo tomo_3c6038, Batch 13/16, Loss: 0.9917\nEpoch 2, Tomo tomo_3c6038, Batch 14/16, Loss: 0.9913\nEpoch 2, Tomo tomo_3c6038, Batch 15/16, Loss: 0.9977\nEpoch 2, Tomo tomo_3c6038, Batch 16/16, Loss: 0.9953\nEpoch 2, Tomo tomo_3c6038 completed, Average Loss: 0.9957\nWARNING - Completed training on tomogram tomo_3c6038, Loss: 0.9957\nCompleted training on tomogram tomo_3c6038, Loss: 0.9957\nProcessed 4/8 tomograms\nWARNING - Processed 4/8 tomograms\nCleaning memory for batch: ['tomo_3c6038', 'tomo_369cce', 'tomo_cff77a', 'tomo_60d478']\nWARNING - Completed parallel download for tomogram tomo_4e38b8\nWARNING - Completed parallel download for tomogram tomo_98d455\nWARNING - Completed parallel download for tomogram tomo_1c38fd\nWARNING - Completed parallel download for tomogram tomo_b7d014\nWARNING - Prepared patches for tomogram tomo_4e38b8\nWARNING - Prepared patches for tomogram tomo_98d455\nWARNING - Prepared patches for tomogram tomo_1c38fd\nWARNING - Prepared patches for tomogram tomo_b7d014\nWARNING - Batch prefetch time for ['tomo_1c38fd', 'tomo_98d455', 'tomo_4e38b8', 'tomo_b7d014']: 86.22 seconds\nWARNING - Processing batch of tomograms: ['tomo_1c38fd', 'tomo_98d455', 'tomo_4e38b8', 'tomo_b7d014']\nProcessing batch of tomograms: ['tomo_1c38fd', 'tomo_98d455', 'tomo_4e38b8', 'tomo_b7d014']\nWARNING - Training on tomogram tomo_4e38b8\nTraining on tomogram tomo_4e38b8\nEpoch 2, Tomo tomo_4e38b8, Batch 1/16, Loss: 0.9932\nEpoch 2, Tomo tomo_4e38b8, Batch 2/16, Loss: 0.9953\nEpoch 2, Tomo tomo_4e38b8, Batch 3/16, Loss: 0.9978\nEpoch 2, Tomo tomo_4e38b8, Batch 4/16, Loss: 0.9952\nEpoch 2, Tomo tomo_4e38b8, Batch 5/16, Loss: 0.9953\nEpoch 2, Tomo tomo_4e38b8, Batch 6/16, Loss: 0.9952\nEpoch 2, Tomo tomo_4e38b8, Batch 7/16, Loss: 0.9950\nEpoch 2, Tomo tomo_4e38b8, Batch 8/16, Loss: 0.9952\nEpoch 2, Tomo tomo_4e38b8, Batch 9/16, Loss: 0.9951\nEpoch 2, Tomo tomo_4e38b8, Batch 10/16, Loss: 0.9950\nEpoch 2, Tomo tomo_4e38b8, Batch 11/16, Loss: 0.9946\nEpoch 2, Tomo tomo_4e38b8, Batch 12/16, Loss: 0.9923\nEpoch 2, Tomo tomo_4e38b8, Batch 13/16, Loss: 0.9948\nEpoch 2, Tomo tomo_4e38b8, Batch 14/16, Loss: 1.0000\nEpoch 2, Tomo tomo_4e38b8, Batch 15/16, Loss: 0.9974\nEpoch 2, Tomo tomo_4e38b8, Batch 16/16, Loss: 0.9896\nEpoch 2, Tomo tomo_4e38b8 completed, Average Loss: 0.9951\nWARNING - Completed training on tomogram tomo_4e38b8, Loss: 0.9951\nCompleted training on tomogram tomo_4e38b8, Loss: 0.9951\nProcessed 5/8 tomograms\nWARNING - Processed 5/8 tomograms\nWARNING - Training on tomogram tomo_98d455\nTraining on tomogram tomo_98d455\nEpoch 2, Tomo tomo_98d455, Batch 1/16, Loss: 0.9955\nEpoch 2, Tomo tomo_98d455, Batch 2/16, Loss: 0.9949\nEpoch 2, Tomo tomo_98d455, Batch 3/16, Loss: 0.9949\nEpoch 2, Tomo tomo_98d455, Batch 4/16, Loss: 0.9949\nEpoch 2, Tomo tomo_98d455, Batch 5/16, Loss: 1.0000\nEpoch 2, Tomo tomo_98d455, Batch 6/16, Loss: 0.9951\nEpoch 2, Tomo tomo_98d455, Batch 7/16, Loss: 0.9925\nEpoch 2, Tomo tomo_98d455, Batch 8/16, Loss: 0.9952\nEpoch 2, Tomo tomo_98d455, Batch 9/16, Loss: 0.9949\nEpoch 2, Tomo tomo_98d455, Batch 10/16, Loss: 0.9924\nEpoch 2, Tomo tomo_98d455, Batch 11/16, Loss: 0.9951\nEpoch 2, Tomo tomo_98d455, Batch 12/16, Loss: 0.9948\nEpoch 2, Tomo tomo_98d455, Batch 13/16, Loss: 0.9950\nEpoch 2, Tomo tomo_98d455, Batch 14/16, Loss: 0.9974\nEpoch 2, Tomo tomo_98d455, Batch 15/16, Loss: 0.9973\nEpoch 2, Tomo tomo_98d455, Batch 16/16, Loss: 0.9948\nEpoch 2, Tomo tomo_98d455 completed, Average Loss: 0.9953\nWARNING - Completed training on tomogram tomo_98d455, Loss: 0.9953\nCompleted training on tomogram tomo_98d455, Loss: 0.9953\nProcessed 6/8 tomograms\nWARNING - Processed 6/8 tomograms\nWARNING - Training on tomogram tomo_1c38fd\nTraining on tomogram tomo_1c38fd\nEpoch 2, Tomo tomo_1c38fd, Batch 1/16, Loss: 0.9928\nEpoch 2, Tomo tomo_1c38fd, Batch 2/16, Loss: 0.9895\nEpoch 2, Tomo tomo_1c38fd, Batch 3/16, Loss: 0.9946\nEpoch 2, Tomo tomo_1c38fd, Batch 4/16, Loss: 0.9973\nEpoch 2, Tomo tomo_1c38fd, Batch 5/16, Loss: 0.9921\nEpoch 2, Tomo tomo_1c38fd, Batch 6/16, Loss: 0.9920\nEpoch 2, Tomo tomo_1c38fd, Batch 7/16, Loss: 1.0000\nEpoch 2, Tomo tomo_1c38fd, Batch 8/16, Loss: 0.9946\nEpoch 2, Tomo tomo_1c38fd, Batch 9/16, Loss: 0.9945\nEpoch 2, Tomo tomo_1c38fd, Batch 10/16, Loss: 0.9936\nEpoch 2, Tomo tomo_1c38fd, Batch 11/16, Loss: 0.9943\nEpoch 2, Tomo tomo_1c38fd, Batch 12/16, Loss: 0.9944\nEpoch 2, Tomo tomo_1c38fd, Batch 13/16, Loss: 1.0000\nEpoch 2, Tomo tomo_1c38fd, Batch 14/16, Loss: 1.0000\nEpoch 2, Tomo tomo_1c38fd, Batch 15/16, Loss: 0.9915\nEpoch 2, Tomo tomo_1c38fd, Batch 16/16, Loss: 0.9962\nEpoch 2, Tomo tomo_1c38fd completed, Average Loss: 0.9948\nWARNING - Completed training on tomogram tomo_1c38fd, Loss: 0.9948\nCompleted training on tomogram tomo_1c38fd, Loss: 0.9948\nProcessed 7/8 tomograms\nWARNING - Processed 7/8 tomograms\nWARNING - Training on tomogram tomo_b7d014\nTraining on tomogram tomo_b7d014\nEpoch 2, Tomo tomo_b7d014, Batch 1/16, Loss: 0.9992\nEpoch 2, Tomo tomo_b7d014, Batch 2/16, Loss: 1.0000\nEpoch 2, Tomo tomo_b7d014, Batch 3/16, Loss: 0.9953\nEpoch 2, Tomo tomo_b7d014, Batch 4/16, Loss: 0.9947\nEpoch 2, Tomo tomo_b7d014, Batch 5/16, Loss: 0.9962\nEpoch 2, Tomo tomo_b7d014, Batch 6/16, Loss: 0.9950\nEpoch 2, Tomo tomo_b7d014, Batch 7/16, Loss: 0.9946\nEpoch 2, Tomo tomo_b7d014, Batch 8/16, Loss: 0.9947\nEpoch 2, Tomo tomo_b7d014, Batch 9/16, Loss: 0.9955\nEpoch 2, Tomo tomo_b7d014, Batch 10/16, Loss: 0.9946\nEpoch 2, Tomo tomo_b7d014, Batch 11/16, Loss: 0.9943\nEpoch 2, Tomo tomo_b7d014, Batch 12/16, Loss: 0.9949\nEpoch 2, Tomo tomo_b7d014, Batch 13/16, Loss: 0.9946\nEpoch 2, Tomo tomo_b7d014, Batch 14/16, Loss: 0.9976\nEpoch 2, Tomo tomo_b7d014, Batch 15/16, Loss: 0.9949\nEpoch 2, Tomo tomo_b7d014, Batch 16/16, Loss: 0.9954\nEpoch 2, Tomo tomo_b7d014 completed, Average Loss: 0.9957\nWARNING - Completed training on tomogram tomo_b7d014, Loss: 0.9957\nCompleted training on tomogram tomo_b7d014, Loss: 0.9957\nProcessed 8/8 tomograms\nWARNING - Processed 8/8 tomograms\nCleaning memory for batch: ['tomo_1c38fd', 'tomo_98d455', 'tomo_4e38b8', 'tomo_b7d014']\n","output_type":"stream"},{"name":"stderr","text":"Validation:   0%|          | 0/5 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"WARNING - Validating tomogram tomo_6303f0\n","output_type":"stream"},{"name":"stderr","text":"Validation:  20%|██        | 1/5 [00:06<00:25,  6.35s/it]","output_type":"stream"},{"name":"stdout","text":"WARNING - Validating tomogram tomo_e5a091\n","output_type":"stream"},{"name":"stderr","text":"Validation:  40%|████      | 2/5 [00:10<00:14,  4.89s/it]","output_type":"stream"},{"name":"stdout","text":"WARNING - Validating tomogram tomo_138018\n","output_type":"stream"},{"name":"stderr","text":"Validation:  60%|██████    | 3/5 [00:12<00:07,  3.54s/it]","output_type":"stream"},{"name":"stdout","text":"WARNING - Validating tomogram tomo_f427b3\n","output_type":"stream"},{"name":"stderr","text":"Validation:  80%|████████  | 4/5 [00:13<00:02,  2.81s/it]","output_type":"stream"},{"name":"stdout","text":"WARNING - Validating tomogram tomo_ab804d\nWARNING - Saved visualization for tomo_ab804d\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 5/5 [00:39<00:00,  7.91s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 2/2, Train Loss: 0.9957, Val Loss: 0.1247\nTEMP Saved training metrics to training_metrics.csv\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Saved checkpoint and best model\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# 1 Hyperparameter Tuning (Peak Detection Threshold)\n# 2 Predict on the validation set,\n# 3 Extract motor locations using peak detection\n# 4 Tune the threshold to maximize the Fβ-score (β=2).\n# 5 Using competition's metric\n\n# Metric implementation (from provided notebook)\ndef distance_metric(solution, submission, thresh_ratio, min_radius):\n    coordinate_cols = ['Motor axis 0', 'Motor axis 1', 'Motor axis 2']\n    label_tensor = solution[coordinate_cols].values.reshape(len(solution), -1, len(coordinate_cols))\n    predicted_tensor = submission[coordinate_cols].values.reshape(len(submission), -1, len(coordinate_cols))\n    solution['distance'] = np.linalg.norm(label_tensor - predicted_tensor, axis=2).min(axis=1)\n    solution['thresholds'] = solution['Voxel spacing'].apply(lambda x: (min_radius * thresh_ratio) / x)\n    solution['predictions'] = submission['Has motor'].values\n    solution.loc[(solution['distance'] > solution['thresholds']) & (solution['Has motor'] == 1) & (submission['Has motor'] == 1), 'predictions'] = 0\n    return solution['predictions'].values\n\ndef score(solution, submission, min_radius, beta):\n    solution = solution.sort_values('tomo_id').reset_index(drop=True)\n    submission = submission.sort_values('tomo_id').reset_index(drop=True)\n    if not solution['tomo_id'].eq(submission['tomo_id']).all():\n        raise ValueError('Submitted tomo_id values do not match')\n    submission['Has motor'] = 1\n    select = (submission[['Motor axis 0', 'Motor axis 1', 'Motor axis 2']] == -1).any(axis='columns')\n    submission.loc[select, 'Has motor'] = 0\n    predictions = distance_metric(solution, submission, thresh_ratio=1.0, min_radius=min_radius)\n    return sklearn.metrics.fbeta_score(solution['Has motor'].values, predictions, beta=beta)\n\ndef predict_full_volume(model, volume, patch_size=(128, 128, 128), stride=64, batch_size=8):\n    model.eval()\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    \n    # Validate and reshape volume\n    if isinstance(volume, np.ndarray):\n        volume = torch.from_numpy(volume).float()\n    if len(volume.shape) == 3:  # (z, y, x) -> (1, 1, z, y, x)\n        volume = volume.unsqueeze(0).unsqueeze(0)\n    elif len(volume.shape) == 4:  # (channels, z, y, x) -> (1, channels, z, y, x)\n        volume = volume.unsqueeze(0)\n    elif len(volume.shape) != 5:\n        raise ValueError(f\"Expected volume with 3-5 dimensions, got shape {volume.shape}\")\n    \n    volume = volume.to(device, non_blocking=True)\n    batch, channels, z_size, y_size, x_size = volume.shape\n    pz, py, px = patch_size\n    output = torch.zeros_like(volume, device=device)\n    counts = torch.zeros_like(volume, device=device)\n    \n    # Collect patch coordinates\n    patches = []\n    coords = []\n    for z in range(0, z_size, stride):\n        for y in range(0, y_size, stride):\n            for x in range(0, x_size, stride):\n                z_end, y_end, x_end = z + pz, y + py, x + px\n                coords.append((z, y, x, min(z_end, z_size), min(y_end, y_size), min(x_end, x_size)))\n                patch = volume[:, :, z:min(z_end, z_size), y:min(y_end, y_size), x:min(x_end, x_size)]\n                pad_z, pad_y, pad_x = max(0, z_end - z_size), max(0, y_end - y_size), max(0, x_end - x_size)\n                if pad_z > 0 or pad_y > 0 or pad_x > 0:\n                    patch = torch.nn.functional.pad(patch, (0, pad_x, 0, pad_y, 0, pad_z))\n                patches.append(patch)\n    \n    # Process patches in batches\n    with torch.no_grad():\n        for i in range(0, len(patches), batch_size):\n            batch_patches = torch.cat(patches[i:i+batch_size], dim=0).to(device, non_blocking=True)\n            batch_out = torch.sigmoid(model(batch_patches))\n            for j, (z, y, x, z_end, y_end, x_end) in enumerate(coords[i:i+batch_size]):\n                output[:, :, z:z_end, y:y_end, x:x_end] += batch_out[j, :, :z_end-z, :y_end-y, :x_end-x]\n                counts[:, :, z:z_end, y:y_end, x:x_end] += 1\n    \n    output = output / (counts + 1e-8)\n    logger.info(f\"Predicted volume shape: {output.shape}, GPU memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n    return output.cpu().numpy()\n\n# Extract motor location from predicted mask\n# extract_motor_location (unchanged, but added logging)\ndef extract_motor_location(mask, threshold):\n    mask = mask.squeeze()\n    max_val = mask.max()\n    logger.info(f\"Extracting motor location, mask max: {max_val:.4f}, threshold: {threshold:.2f}\")\n    if max_val < threshold:\n        return -1, -1, -1, 0\n    z, y, x = np.unravel_index(np.argmax(mask), mask.shape)\n    region = mask[max(0, z-5):z+6, max(0, y-5):y+6, max(0, x-5):x+6]\n    if region.size == 0:\n        logger.info(f\"Motor at ({z}, {y}, {x}), region empty\")\n        return z, y, x, 1\n    z_offset, y_offset, x_offset = center_of_mass(region)\n    z, y, x = z + z_offset - 5, y + y_offset - 5, x + x_offset - 5\n    logger.info(f\"Motor at ({z:.2f}, {y:.2f}, {x:.2f})\")\n    return z, y, x, 1\n\n# Tune peak detection threshold\ndef tune_threshold(model, val_ids, gcs_preprocessed_path, gcs_precomputed_path, local_dir, labels_df, thresholds=np.linspace(0.1, 0.9, 9)):\n    best_model_path = \"/kaggle/working/best_model.pth\"\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    if os.path.exists(best_model_path):\n        model.load_state_dict(torch.load(best_model_path, weights_only=True))\n        print(\"Loaded best_model.pth\", flush=True)\n        logger.info(\"Loaded best_model.pth\")\n    else:\n        print(\"Warning: best_model.pth not found, using current model state\", flush=True)\n        logger.warning(\"best_model.pth not found, using current model state\")\n    model.to(device).eval()\n    best_threshold = 0.5\n    best_fbeta = 0.0\n    thresholds_list = []\n    fbeta_scores = []\n\n    # Check tomo_ab804d motor count\n    tomo_labels = labels_df[labels_df[\"tomo_id\"] == \"tomo_ab804d\"]\n    if not tomo_labels.empty:\n        num_motors = tomo_labels.iloc[0][\"Number of motors\"]\n        logger.info(f\"tomo_ab804d has {num_motors} motors\")\n        print(f\"tomo_ab804d has {num_motors} motors\", flush=True)\n    \n    for threshold in thresholds:\n        predictions = []\n        # Create DataLoader for validation tomograms\n        dataset = [TomogramDataset(tomo_id, gcs_preprocessed_path, local_dir, mode=\"val\") for tomo_id in val_ids]\n        loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=4, pin_memory=True)\n        \n        for tomo_idx, (volume, _) in enumerate(tqdm(loader, desc=f\"Tuning threshold {threshold:.2f}\")):\n            tomo_id = val_ids[tomo_idx]\n            volume = volume.to(device, non_blocking=True)\n            logger.info(f\"Volume shape for {tomo_id}: {volume.shape}\")\n            pred_mask = predict_full_volume(model, volume, patch_size=(128, 128, 128), stride=64, batch_size=8)\n            z, y, x, has_motor = extract_motor_location(pred_mask, threshold)\n            \n            if tomo_id == val_ids[0]:  # Visualize first tomogram\n                mask_path = os.path.join(local_dir, f\"{tomo_id}_mask.npy\")\n                if not os.path.exists(mask_path):\n                    _, mask_path = download_npy_and_mask(tomo_id, gcs_preprocessed_path, gcs_precomputed_path, \"train\", local_dir)\n                gt_mask = np.load(mask_path)\n                slice_idx = volume.shape[2] // 2\n                tomo_slice = volume[0, 0, slice_idx, :, :].cpu().numpy()\n                pred_slice = pred_mask[0, 0, slice_idx, :, :]\n                gt_slice = gt_mask[slice_idx, :, :]\n                gt_row = labels_df[labels_df[\"tomo_id\"] == tomo_id].iloc[0]\n                gt_z, gt_y, gt_x = gt_row[\"Motor axis 0\"], gt_row[\"Motor axis 1\"], gt_row[\"Motor axis 2\"]\n\n                plt.figure(figsize=(15, 5))\n                plt.subplot(1, 3, 1)\n                plt.imshow(tomo_slice, cmap=\"gray\")\n                plt.title(f\"Tomogram Slice (z={slice_idx})\")\n                plt.axis(\"off\")\n                plt.subplot(1, 3, 2)\n                plt.imshow(pred_slice, cmap=\"hot\")\n                if has_motor:\n                    plt.scatter(x, y, c=\"blue\", marker=\"x\", s=100, label=\"Predicted\")\n                if gt_z != -1:\n                    plt.scatter(gt_x, gt_y, c=\"green\", marker=\"o\", s=100, label=\"Ground Truth\")\n                plt.title(\"Predicted Mask with Motor Locations\")\n                plt.legend()\n                plt.axis(\"off\")\n                plt.subplot(1, 3, 3)\n                plt.imshow(gt_slice, cmap=\"hot\")\n                if gt_z != -1:\n                    plt.scatter(gt_x, gt_y, c=\"green\", marker=\"o\", s=100, label=\"Ground Truth\")\n                plt.title(\"Ground Truth Mask\")\n                plt.legend()\n                plt.axis(\"off\")\n                plt.tight_layout()\n                plt.savefig(f\"/kaggle/working/tune_viz_{tomo_id}_threshold_{threshold:.2f}.png\")\n                plt.close()\n                clean_memory([tomo_id], local_dir)\n            \n            predictions.append({\"tomo_id\": tomo_id, \"Motor axis 0\": z, \"Motor axis 1\": y, \"Motor axis 2\": x, \"Has motor\": has_motor})\n            clean_memory([tomo_id], local_dir)\n            torch.cuda.empty_cache()  # Clear GPU memory\n            logger.info(f\"Cleared GPU memory after {tomo_id}, usage: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n        \n        # Create submission and solution DataFrames\n        submission_df = pd.DataFrame(predictions)\n        solution_data = []\n        for tomo_id in val_ids:\n            tomo_labels = labels_df[labels_df[\"tomo_id\"] == tomo_id].iloc[0]\n            solution_data.append({\n                \"tomo_id\": tomo_id,\n                \"Motor axis 0\": tomo_labels[\"Motor axis 0\"],\n                \"Motor axis 1\": tomo_labels[\"Motor axis 1\"],\n                \"Motor axis 2\": tomo_labels[\"Motor axis 2\"],\n                \"Voxel spacing\": tomo_labels[\"Voxel spacing\"],\n                \"Has motor\": 1 if tomo_labels[\"Number of motors\"] > 0 else 0\n            })\n        solution_df = pd.DataFrame(solution_data)\n        fbeta = score(solution_df, submission_df, min_radius=1000, beta=2)\n        logger.info(f\"Threshold {threshold:.2f}, Fβ-score: {fbeta:.4f}, TP: {((solution_df['Has motor'] == 1) & (submission_df['Has motor'] == 1)).sum()}, \"\n                    f\"FP: {((solution_df['Has motor'] == 0) & (submission_df['Has motor'] == 1)).sum()}, \"\n                    f\"FN: {((solution_df['Has motor'] == 1) & (submission_df['Has motor'] == 0)).sum()}\")\n        print(f\"Threshold {threshold:.2f}, Fβ-score: {fbeta:.4f}\", flush=True)\n        thresholds_list.append(threshold)\n        fbeta_scores.append(fbeta)\n        \n        if fbeta > best_fbeta:\n            best_fbeta = fbeta\n            best_threshold = threshold\n    \n    # Plot Fβ-scores\n    plt.figure(figsize=(8, 5))\n    plt.plot(thresholds_list, fbeta_scores, marker=\"o\")\n    plt.xlabel(\"Threshold\")\n    plt.ylabel(\"Fβ-score (β=2)\")\n    plt.title(\"Fβ-score vs. Peak Detection Threshold\")\n    plt.grid(True)\n    plt.savefig(\"/kaggle/working/fbeta_vs_threshold.png\")\n    plt.close()\n    print(f\"Best threshold: {best_threshold:.2f}, Best Fβ-score: {best_fbeta:.4f}\", flush=True)\n    logger.info(f\"Best threshold: {best_threshold:.2f}, Best Fβ-score: {best_fbeta:.4f}\")\n    return best_threshold","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T03:07:08.389273Z","iopub.execute_input":"2025-05-22T03:07:08.39002Z","iopub.status.idle":"2025-05-22T03:07:08.419066Z","shell.execute_reply.started":"2025-05-22T03:07:08.38999Z","shell.execute_reply":"2025-05-22T03:07:08.418284Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# predict_test\ndef predict_test(model, test_ids, gcs_preprocessed_path, local_dir, threshold):\n    best_model_path = \"/kaggle/working/checkpoint.pth\"\n    if os.path.exists(best_model_path):\n        checkpoint = torch.load(best_model_path, weights_only=True)\n        model.load_state_dict(checkpoint['model_state_dict'])\n        print(\"Loaded checkpoint.pth\", flush=True)\n        logger.info(\"Loaded checkpoint.pth\")\n    model.eval()\n    predictions = []\n    for tomo_id in tqdm(test_ids, desc=\"Predicting on test set\"):\n        dataset = TomogramDataset(tomo_id, gcs_preprocessed_path, local_dir, mode=\"test\")\n        dataset.load()\n        volume, _ = dataset[0]\n        pred_mask = predict_full_volume(model, volume)\n        z, y, x, has_motor = extract_motor_location(pred_mask, threshold)\n        predictions.append({\"tomo_id\": tomo_id, \"Motor axis 0\": z, \"Motor axis 1\": y, \"Motor axis 2\": x})\n        dataset.clear()\n    return pd.DataFrame(predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T03:07:24.672958Z","iopub.execute_input":"2025-05-22T03:07:24.673654Z","iopub.status.idle":"2025-05-22T03:07:24.679041Z","shell.execute_reply.started":"2025-05-22T03:07:24.673632Z","shell.execute_reply":"2025-05-22T03:07:24.678216Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Run pipeline\nprint(\"Starting hyperparameter tuning...\")\nlogger.info(\"Starting hyperparameter tuning...\")\nbest_threshold = tune_threshold(model, val_ids, gcs_preprocessed_path, gcs_precomputed_path, local_dir, labels_df)\nprint(\"Generating test predictions...\")\nlogger.info(\"Generating test predictions...\")\nsubmission_df = predict_test(model, test_ids, gcs_preprocessed_path, local_dir, best_threshold)\nsubmission_df.to_csv(\"submission.csv\", index=False)\nprint(\"Submission file created: submission.csv\")\nlogger.info(\"Submission file created: submission.csv\")\n# Finish the wandb run\n#wandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T03:07:40.568187Z","iopub.execute_input":"2025-05-22T03:07:40.568776Z","iopub.status.idle":"2025-05-22T04:47:58.065772Z","shell.execute_reply.started":"2025-05-22T03:07:40.568753Z","shell.execute_reply":"2025-05-22T04:47:58.063078Z"}},"outputs":[{"name":"stdout","text":"Starting hyperparameter tuning...\nLoaded best_model.pth\ntomo_ab804d has 0 motors\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:   0%|          | 0/65 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_ab804d (shape: (800, 928, 960))\nLoaded mask tomo_ab804d (min/max: 0.0/0.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:   2%|▏         | 1/65 [03:25<3:39:12, 205.51s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_f427b3 (shape: (300, 959, 928))\nLoaded mask tomo_f427b3 (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:   3%|▎         | 2/65 [04:42<2:16:26, 129.94s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_6303f0 (shape: (300, 960, 928))\nLoaded mask tomo_6303f0 (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:   5%|▍         | 3/65 [05:57<1:48:15, 104.77s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_e5a091 (shape: (500, 960, 928))\nLoaded mask tomo_e5a091 (min/max: 0.0/0.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:   6%|▌         | 4/65 [08:01<1:54:23, 112.51s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_138018 (shape: (300, 959, 928))\nLoaded mask tomo_138018 (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:   8%|▊         | 5/65 [09:16<1:38:47, 98.78s/it] ","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_399bd9 (shape: (300, 928, 928))\nLoaded mask tomo_399bd9 (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:   9%|▉         | 6/65 [10:28<1:28:22, 89.87s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_656915 (shape: (500, 924, 956))\nLoaded mask tomo_656915 (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  11%|█         | 7/65 [12:32<1:37:40, 101.05s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_a81e01 (shape: (300, 959, 928))\nLoaded mask tomo_a81e01 (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  12%|█▏        | 8/65 [13:49<1:28:37, 93.29s/it] ","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_0363f2 (shape: (300, 960, 928))\nLoaded mask tomo_0363f2 (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  14%|█▍        | 9/65 [15:04<1:21:41, 87.53s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_1ab322 (shape: (300, 960, 928))\nLoaded mask tomo_1ab322 (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  15%|█▌        | 10/65 [16:18<1:16:23, 83.34s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_417e5f (shape: (300, 960, 928))\nLoaded mask tomo_417e5f (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  17%|█▋        | 11/65 [17:36<1:13:35, 81.78s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_7036ee (shape: (300, 960, 928))\nLoaded mask tomo_7036ee (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  18%|█▊        | 12/65 [18:54<1:11:07, 80.53s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_c8f3ce (shape: (300, 928, 928))\nLoaded mask tomo_c8f3ce (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  20%|██        | 13/65 [20:08<1:08:08, 78.62s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_49725c (shape: (300, 959, 928))\nLoaded mask tomo_49725c (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  22%|██▏       | 14/65 [21:26<1:06:41, 78.46s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_db2a10 (shape: (300, 928, 928))\nLoaded mask tomo_db2a10 (min/max: 0.0/0.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  23%|██▎       | 15/65 [22:40<1:04:20, 77.22s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_71ece1 (shape: (300, 928, 928))\nLoaded mask tomo_71ece1 (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  25%|██▍       | 16/65 [23:57<1:03:00, 77.15s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_d916dc (shape: (300, 960, 928))\nLoaded mask tomo_d916dc (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  26%|██▌       | 17/65 [25:13<1:01:24, 76.75s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_1b82d1 (shape: (500, 924, 956))\nLoaded mask tomo_1b82d1 (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  28%|██▊       | 18/65 [27:22<1:12:16, 92.27s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_b80310 (shape: (300, 928, 928))\nLoaded mask tomo_b80310 (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  29%|██▉       | 19/65 [28:36<1:06:41, 87.00s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_e764a7 (shape: (500, 960, 928))\nLoaded mask tomo_e764a7 (min/max: 0.0/0.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  31%|███       | 20/65 [30:42<1:14:04, 98.76s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_918e2b (shape: (300, 960, 928))\nLoaded mask tomo_918e2b (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  32%|███▏      | 21/65 [31:59<1:07:31, 92.08s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_bd42fa (shape: (500, 928, 960))\nLoaded mask tomo_bd42fa (min/max: 0.0/0.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  34%|███▍      | 22/65 [34:09<1:14:06, 103.41s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_da79d8 (shape: (500, 924, 956))\nLoaded mask tomo_da79d8 (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  35%|███▌      | 23/65 [36:18<1:17:49, 111.17s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_db6051 (shape: (500, 928, 960))\nLoaded mask tomo_db6051 (min/max: 0.0/0.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  37%|███▋      | 24/65 [38:22<1:18:38, 115.10s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_a9d067 (shape: (500, 924, 956))\nLoaded mask tomo_a9d067 (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  38%|███▊      | 25/65 [40:28<1:18:47, 118.20s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_61e947 (shape: (800, 928, 960))\nLoaded mask tomo_61e947 (min/max: 0.0/0.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  40%|████      | 26/65 [43:55<1:34:06, 144.77s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_85708b (shape: (800, 928, 960))\nLoaded mask tomo_85708b (min/max: 0.0/0.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  42%|████▏     | 27/65 [47:22<1:43:39, 163.68s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_1da097 (shape: (500, 928, 960))\nLoaded mask tomo_1da097 (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  43%|████▎     | 28/65 [49:24<1:33:13, 151.19s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_3183d2 (shape: (300, 959, 928))\nLoaded mask tomo_3183d2 (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  45%|████▍     | 29/65 [50:39<1:16:56, 128.24s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_b2eb0c (shape: (500, 1024, 1440))\nLoaded mask tomo_b2eb0c (min/max: 0.0/0.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  46%|████▌     | 30/65 [54:12<1:29:42, 153.78s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_8f4d60 (shape: (300, 960, 928))\nLoaded mask tomo_8f4d60 (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  48%|████▊     | 31/65 [55:27<1:13:42, 130.06s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_cd1a7c (shape: (300, 960, 928))\nLoaded mask tomo_cd1a7c (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  49%|████▉     | 32/65 [56:43<1:02:30, 113.65s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_5f235a (shape: (300, 960, 928))\nLoaded mask tomo_5f235a (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  51%|█████     | 33/65 [57:57<54:21, 101.92s/it]  ","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_8f063a (shape: (300, 960, 928))\nLoaded mask tomo_8f063a (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  52%|█████▏    | 34/65 [59:12<48:25, 93.73s/it] ","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_76a42b (shape: (300, 960, 928))\nLoaded mask tomo_76a42b (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  54%|█████▍    | 35/65 [1:00:26<43:57, 87.90s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_2f3261 (shape: (300, 960, 928))\nLoaded mask tomo_2f3261 (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  55%|█████▌    | 36/65 [1:01:41<40:36, 84.02s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_c00ab5 (shape: (300, 960, 928))\nLoaded mask tomo_c00ab5 (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  57%|█████▋    | 37/65 [1:02:56<37:57, 81.35s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_5764d6 (shape: (500, 928, 960))\nLoaded mask tomo_5764d6 (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  58%|█████▊    | 38/65 [1:05:05<43:00, 95.59s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_8d2d48 (shape: (300, 924, 956))\nLoaded mask tomo_8d2d48 (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  60%|██████    | 39/65 [1:06:20<38:44, 89.39s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_616f0b (shape: (300, 959, 928))\nLoaded mask tomo_616f0b (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  62%|██████▏   | 40/65 [1:07:34<35:21, 84.87s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_39b15b (shape: (500, 924, 956))\nLoaded mask tomo_39b15b (min/max: 0.0/0.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  63%|██████▎   | 41/65 [1:09:45<39:24, 98.54s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_bebadf (shape: (300, 960, 928))\nLoaded mask tomo_bebadf (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  65%|██████▍   | 42/65 [1:11:01<35:16, 92.03s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_e34af8 (shape: (300, 960, 928))\nLoaded mask tomo_e34af8 (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  66%|██████▌   | 43/65 [1:12:16<31:49, 86.82s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_101279 (shape: (300, 928, 928))\nLoaded mask tomo_101279 (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  68%|██████▊   | 44/65 [1:13:30<29:04, 83.05s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_7cf523 (shape: (300, 960, 928))\nLoaded mask tomo_7cf523 (min/max: 0.0/0.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  69%|██████▉   | 45/65 [1:14:45<26:53, 80.67s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_3a3519 (shape: (300, 960, 928))\nLoaded mask tomo_3a3519 (min/max: 0.0/0.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  71%|███████   | 46/65 [1:16:03<25:16, 79.82s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_a2a928 (shape: (300, 960, 928))\nLoaded mask tomo_a2a928 (min/max: 0.0/0.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  72%|███████▏  | 47/65 [1:17:22<23:51, 79.52s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_983fce (shape: (500, 928, 960))\nLoaded mask tomo_983fce (min/max: 0.0/0.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  74%|███████▍  | 48/65 [1:19:32<26:48, 94.63s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_f94504 (shape: (500, 924, 956))\nLoaded mask tomo_f94504 (min/max: 0.0/0.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  75%|███████▌  | 49/65 [1:21:44<28:11, 105.70s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_aec312 (shape: (500, 924, 956))\nLoaded mask tomo_aec312 (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  77%|███████▋  | 50/65 [1:23:50<27:58, 111.89s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_1dc5f9 (shape: (500, 924, 956))\nLoaded mask tomo_1dc5f9 (min/max: 0.0/0.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  78%|███████▊  | 51/65 [1:25:54<26:56, 115.47s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_23ce49 (shape: (300, 959, 928))\nLoaded mask tomo_23ce49 (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  80%|████████  | 52/65 [1:27:09<22:25, 103.47s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_e32b81 (shape: (300, 960, 928))\nLoaded mask tomo_e32b81 (min/max: 0.0/0.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  82%|████████▏ | 53/65 [1:28:23<18:56, 94.67s/it] ","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_806a8f (shape: (300, 960, 928))\nLoaded mask tomo_806a8f (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  83%|████████▎ | 54/65 [1:29:37<16:13, 88.47s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_134bb0 (shape: (300, 959, 928))\nLoaded mask tomo_134bb0 (min/max: 0.0/1.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  85%|████████▍ | 55/65 [1:30:52<14:03, 84.31s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_0a180f (shape: (800, 928, 960))\nLoaded mask tomo_0a180f (min/max: 0.0/0.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  86%|████████▌ | 56/65 [1:34:20<18:13, 121.51s/it]","output_type":"stream"},{"name":"stdout","text":"Loaded tomogram tomo_c77de0 (shape: (494, 1912, 1847))\nLoaded mask tomo_c77de0 (min/max: 0.0/0.0)\n","output_type":"stream"},{"name":"stderr","text":"Tuning threshold 0.10:  86%|████████▌ | 56/65 [1:40:17<16:07, 107.45s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/807396157.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting hyperparameter tuning...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting hyperparameter tuning...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbest_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtune_threshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcs_preprocessed_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcs_precomputed_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Generating test predictions...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Generating test predictions...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_35/515911315.py\u001b[0m in \u001b[0;36mtune_threshold\u001b[0;34m(model, val_ids, gcs_preprocessed_path, gcs_precomputed_path, local_dir, labels_df, thresholds)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mvolume\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Volume shape for {tomo_id}: {volume.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mpred_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_full_volume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_motor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_motor_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"tomo_id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtomo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Motor axis 0\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Motor axis 1\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Motor axis 2\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Has motor\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhas_motor\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_35/515911315.py\u001b[0m in \u001b[0;36mpredict_full_volume\u001b[0;34m(model, volume, patch_size, stride)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mpz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvolume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvolume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 6.50 GiB. GPU 0 has a total capacity of 14.74 GiB of which 1.18 GiB is free. Process 4411 has 13.56 GiB memory in use. Of the allocated memory 13.07 GiB is allocated by PyTorch, and 51.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 6.50 GiB. GPU 0 has a total capacity of 14.74 GiB of which 1.18 GiB is free. Process 4411 has 13.56 GiB memory in use. Of the allocated memory 13.07 GiB is allocated by PyTorch, and 51.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error"}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}