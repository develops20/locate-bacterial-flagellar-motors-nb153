{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":91249,"databundleVersionId":11294684,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nicholas33/byu-2-locate-bacterial-flagellar-motors-nb153?scriptVersionId=235591547\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# Install required packages\n!pip install monai scipy scikit-image wandb imageio gcsfs\n\n# Import libraries\nimport os\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom monai.networks.nets import UNet\nfrom monai.losses import DiceLoss\nimport torch.optim as optim\nfrom scipy.ndimage import gaussian_filter, center_of_mass\nfrom scipy.signal import find_peaks\nimport sklearn.metrics\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport glob\nfrom IPython.display import Video, display\nimport wandb\nimport time\nimport shutil\nimport gcsfs  # Dataset is too big for kaggle - After multiple attempts of uploading, I failed miserably. \nimport gc\n\n# Set random seed for reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T07:38:18.450783Z","iopub.execute_input":"2025-04-23T07:38:18.451826Z","iopub.status.idle":"2025-04-23T07:38:21.817774Z","shell.execute_reply.started":"2025-04-23T07:38:18.451784Z","shell.execute_reply":"2025-04-23T07:38:21.817037Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: monai in /usr/local/lib/python3.11/dist-packages (1.4.0)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.2)\nRequirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.1)\nRequirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.6)\nRequirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (2.37.0)\nRequirement already satisfied: gcsfs in /usr/local/lib/python3.11/dist-packages (2024.10.0)\nRequirement already satisfied: numpy<2.0,>=1.24 in /usr/local/lib/python3.11/dist-packages (from monai) (1.26.4)\nRequirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from monai) (2.5.1+cu124)\nRequirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.4.2)\nRequirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (11.1.0)\nRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.1.10)\nRequirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\nRequirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (7.0.0)\nRequirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.3)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.21.0)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\nRequirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.1)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from gcsfs) (3.11.16)\nRequirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.11/dist-packages (from gcsfs) (4.4.2)\nRequirement already satisfied: fsspec==2024.10.0 in /usr/local/lib/python3.11/dist-packages (from gcsfs) (2024.10.0)\nRequirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.11/dist-packages (from gcsfs) (2.27.0)\nRequirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.11/dist-packages (from gcsfs) (1.2.1)\nRequirement already satisfied: google-cloud-storage in /usr/local/lib/python3.11/dist-packages (from gcsfs) (2.14.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.19.0)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs) (4.9)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.24->monai) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.24->monai) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.24->monai) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.24->monai) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.24->monai) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.24->monai) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.18.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->monai) (1.3.0)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib->gcsfs) (2.0.0)\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs) (1.34.1)\nRequirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs) (2.4.1)\nRequirement already satisfied: google-resumable-media>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs) (2.7.2)\nRequirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs) (1.6.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->gcsfs) (1.67.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.6.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.2.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->monai) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.24->monai) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.24->monai) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0,>=1.24->monai) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0,>=1.24->monai) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0,>=1.24->monai) (2024.2.0)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nwb_token = user_secrets.get_secret(\"WANDB\")\nwandb.login(key=wb_token)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install wandb\n!pip install wandb\n\n# Import wandb\nimport wandb\n# Initialize wandb run\nwandb.init(\n    project=\"byu-bacterial-flagellar-motors\", config={\n    \"learning_rate\": 1e-3,\n    \"epochs\": 50,\n    \"batch_size\": 4,\n    \"patch_size\": (128, 128, 128),\n    \"gaussian_sigma\": 5,\n    \"architecture\": \"3D U-Net\",\n    \"optimizer\": \"Adam\",\n    \"loss_function\": \"DiceLoss\",\n    \"beta\": 2  # For FÎ²-score\n})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fs = gcsfs.GCSFileSystem(token=\"anon\") # Initialize GCS filesystem\n\n# Define GCS path and local directory\ngcs_precomputed_path = \"gs://nb153/precomputedmasks\"\ngcs_preprocessed_path = \"gs://nb153/preprocessed\"\nlocal_dir = \"/kaggle/working/data\"\nos.makedirs(local_dir, exist_ok=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T07:11:40.797199Z","iopub.execute_input":"2025-04-23T07:11:40.79843Z","iopub.status.idle":"2025-04-23T07:11:40.803818Z","shell.execute_reply.started":"2025-04-23T07:11:40.7984Z","shell.execute_reply":"2025-04-23T07:11:40.803203Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Device configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T07:11:42.878011Z","iopub.execute_input":"2025-04-23T07:11:42.878572Z","iopub.status.idle":"2025-04-23T07:11:42.882403Z","shell.execute_reply.started":"2025-04-23T07:11:42.878548Z","shell.execute_reply":"2025-04-23T07:11:42.881555Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Load labels and split data\nlabels_df = pd.read_csv(\"/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/train_labels.csv\")\ntomo_ids = sorted(labels_df[\"tomo_id\"].unique())\nprint(f\"Total tomograms:{len(tomo_ids)}\")\n\n# Split into train/val/test (80/10/10)\ntrain_val_ids, test_ids = sklearn.model_selection.train_test_split(\n    tomo_ids, test_size=0.1, random_state=42\n)\n\ntrain_ids, val_ids = sklearn.model_selection.train_test_split(\n    train_val_ids, test_size=0.1111, random_state=42  # 0.1111 of 90% = 10% of total\n)\nprint(f\"Train IDs: {len(train_ids)}, Val IDs: {len(val_ids)}, Test IDs: {len(test_ids)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T07:11:45.724725Z","iopub.execute_input":"2025-04-23T07:11:45.72502Z","iopub.status.idle":"2025-04-23T07:11:45.738233Z","shell.execute_reply.started":"2025-04-23T07:11:45.724999Z","shell.execute_reply":"2025-04-23T07:11:45.737502Z"}},"outputs":[{"name":"stdout","text":"Total tomograms:648\nTrain IDs: 518, Val IDs: 65, Test IDs: 65\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Download functions\ndef download_npy_from_gcs(tomo_id, gcs_path, split, local_dir):\n    gcs_file_path = f\"{gcs_path}/{split}/{tomo_id}/{tomo_id}.npy\"\n    local_file_path = os.path.join(local_dir, f\"{tomo_id}.npy\")\n    if not os.path.exists(local_file_path):\n        print(f\"Downloading {gcs_file_path} to {local_file_path}\")\n        fs.get(gcs_file_path, local_file_path)\n        print(f\"âœ… Download complete: {tomo_id}\")\n    return local_file_path\n\ndef download_mask_from_gcs(tomo_id, gcs_path, split, local_dir):\n    gcs_file_path = f\"{gcs_path}/{split}/{tomo_id}_mask.npy\"\n    local_file_path = os.path.join(local_dir, f\"{tomo_id}_mask.npy\")\n    if not os.path.exists(local_file_path):\n        print(f\"Downloading {gcs_file_path} to {local_file_path}\")\n        fs.get(gcs_file_path, local_file_path)\n        print(f\"âœ… Download complete: {tomo_id}_mask.npy\")\n    return local_file_path\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T07:11:48.896879Z","iopub.execute_input":"2025-04-23T07:11:48.897202Z","iopub.status.idle":"2025-04-23T07:11:48.903016Z","shell.execute_reply.started":"2025-04-23T07:11:48.897173Z","shell.execute_reply":"2025-04-23T07:11:48.90222Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Function to sample patches from a single tomogram\ndef sample_patches(tomo_id, volume, mask, labels_df, patch_size=(128, 128, 128), patches_per_volume=32):\n    shape = volume.shape\n    patches = []\n    mask_patches = []\n    \n    # Get motor coordinates\n    tomo_labels = labels_df[labels_df[\"tomo_id\"] == tomo_id]\n    motor_coords = []\n    for _, row in tomo_labels.iterrows():\n        if row[\"Number of motors\"] > 0 and row[\"Motor axis 0\"] != -1:\n            z, y, x = int(row[\"Motor axis 0\"]), int(row[\"Motor axis 1\"]), int(row[\"Motor axis 2\"])\n            if 0 <= z < shape[0] and 0 <= y < shape[1] and 0 <= x < shape[2]:\n                motor_coords.append((z, y, x))\n    \n    # Sample half near motors, half random\n    for _ in range(patches_per_volume // 2):\n        if motor_coords:\n            zc, yc, xc = motor_coords[np.random.randint(len(motor_coords))]\n            z = np.clip(zc - patch_size[0]//2 + np.random.randint(-32, 32), 0, shape[0] - patch_size[0])\n            y = np.clip(yc - patch_size[1]//2 + np.random.randint(-32, 32), 0, shape[1] - patch_size[1])\n            x = np.clip(xc - patch_size[2]//2 + np.random.randint(-32, 32), 0, shape[2] - patch_size[2])\n        else:\n            z = np.random.randint(0, max(1, shape[0] - patch_size[0]))\n            y = np.random.randint(0, max(1, shape[1] - patch_size[1]))\n            x = np.random.randint(0, max(1, shape[2] - patch_size[2]))\n        patch = volume[z:z+patch_size[0], y:y+patch_size[1], x:x+patch_size[2]][np.newaxis, ...]\n        mask_patch = mask[z:z+patch_size[0], y:y+patch_size[1], x:x+patch_size[2]][np.newaxis, ...]\n        patches.append(patch)\n        mask_patches.append(mask_patch)\n    \n    for _ in range(patches_per_volume // 2):\n        z = np.random.randint(0, max(1, shape[0] - patch_size[0]))\n        y = np.random.randint(0, max(1, shape[1] - patch_size[1]))\n        x = np.random.randint(0, max(1, shape[2] - patch_size[2]))\n        patch = volume[z:z+patch_size[0], y:y+patch_size[1], x:x+patch_size[2]][np.newaxis, ...]\n        mask_patch = mask[z:z+patch_size[0], y:y+patch_size[1], x:x+patch_size[2]][np.newaxis, ...]\n        patches.append(patch)\n        mask_patches.append(mask_patch)\n    \n    return np.array(patches), np.array(mask_patches)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T07:11:51.276541Z","iopub.execute_input":"2025-04-23T07:11:51.276834Z","iopub.status.idle":"2025-04-23T07:11:51.287566Z","shell.execute_reply.started":"2025-04-23T07:11:51.276815Z","shell.execute_reply":"2025-04-23T07:11:51.28688Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Dataset for patches from a single tomogram\nclass PatchDataset(Dataset):\n    def __init__(self, patches, mask_patches):\n        self.patches = patches\n        self.mask_patches = mask_patches\n    \n    def __len__(self):\n        return len(self.patches)\n    \n    def __getitem__(self, idx):\n        patch = self.patches[idx]\n        mask_patch = self.mask_patches[idx]\n        return torch.tensor(patch, dtype=torch.float32), torch.tensor(mask_patch, dtype=torch.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T07:11:55.380734Z","iopub.execute_input":"2025-04-23T07:11:55.381316Z","iopub.status.idle":"2025-04-23T07:11:55.386038Z","shell.execute_reply.started":"2025-04-23T07:11:55.381291Z","shell.execute_reply":"2025-04-23T07:11:55.385205Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Dataset for full tomograms (validation/test)\nclass TomogramDataset(Dataset):\n    def __init__(self, tomo_id, gcs_preprocessed_path, local_dir, mode=\"test\"):\n        self.tomo_id = tomo_id\n        self.gcs_preprocessed_path = gcs_preprocessed_path\n        self.local_dir = local_dir\n        self.mode = mode\n        self.volume = None\n    \n    def load(self):\n        tomo_path = download_npy_from_gcs(self.tomo_id, self.gcs_preprocessed_path, \"train\" if self.mode == \"val\" else \"test\", self.local_dir)\n        self.volume = np.load(tomo_path)\n    \n    def clear(self):\n        if self.volume is not None:\n            del self.volume\n            self.volume = None\n            tomo_path = os.path.join(self.local_dir, f\"{self.tomo_id}.npy\")\n            if os.path.exists(tomo_path):\n                os.remove(tomo_path)\n            gc.collect()\n    \n    def __len__(self):\n        return 1\n    \n    def __getitem__(self, idx):\n        if self.volume is None:\n            self.load()\n        volume = self.volume[np.newaxis, np.newaxis, ...]\n        return torch.tensor(volume, dtype=torch.float32), self.tomo_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T07:11:58.756578Z","iopub.execute_input":"2025-04-23T07:11:58.757255Z","iopub.status.idle":"2025-04-23T07:11:58.763537Z","shell.execute_reply.started":"2025-04-23T07:11:58.757223Z","shell.execute_reply":"2025-04-23T07:11:58.762737Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Define 3D U-Net model\nmodel = UNet(\n    spatial_dims=3,\n    in_channels=1,\n    out_channels=1,\n    channels=(16, 32, 64, 128, 256),\n    strides=(2, 2, 2, 2),\n    num_res_units=2,\n).to(device)\nprint(\"Model device:\", next(model.parameters()).device)\n\n# Loss and optimizer\ncriterion = DiceLoss(sigmoid=True)  # Sigmoid to handle [0,1] output\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.1, patience=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T07:12:01.901461Z","iopub.execute_input":"2025-04-23T07:12:01.902167Z","iopub.status.idle":"2025-04-23T07:12:02.066324Z","shell.execute_reply.started":"2025-04-23T07:12:01.902122Z","shell.execute_reply":"2025-04-23T07:12:02.065617Z"}},"outputs":[{"name":"stdout","text":"Model device: cuda:0\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"Patch Dataset to read the masked NPY Instead ","metadata":{}},{"cell_type":"code","source":"start_epoch = 0\nbest_val_loss = float(\"inf\")\ntrain_losses = []\nval_losses = []\n\nif os.path.exists(\"checkpoint.pth\"):\n    checkpoint = torch.load(\"checkpoint.pth\", map_location=device)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n    best_val_loss = checkpoint['best_val_loss']\n    start_epoch = checkpoint['epoch'] + 1\n    print(f\"Resumed from epoch {start_epoch}\")\nelse:\n    print(\"No checkpoint found, starting from scratch.\")\n\n# Training function\ndef train_epoch(model, loader, criterion, optimizer, epoch, start_epoch):\n    model.train()\n    epoch_loss = 0.0\n    start = time.time()\n    for i, (inputs, targets) in enumerate(tqdm(loader, desc=\"Training\")):\n        batch_load_time = time.time() - start\n        inputs = inputs.to(device)\n        targets = targets.to(device)\n        optimizer.zero_grad() # forward pass, loss, backward pass, step \n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n        if epoch == start_epoch and i < 2: # Print the first 2 batches \n            print(f\"\\nðŸ•’ Batch {i} load time: {batch_load_time:.2f}s\")\n            print(f\"Inputs shape: {inputs.shape}, min/max: {inputs.min().item():.4f}/{inputs.max().item():.4f}\")\n            print(f\"Targets shape: {targets.shape}, min/max: {targets.min().item():.4f}/{targets.max().item():.4f}\")\n            print(f\"Outputs shape: {outputs.shape}, min/max: {outputs.min().item():.4f}/{outputs.max().item():.4f}\")\n            print(f\"Loss: {loss.item():.4f}\")\n            print(f\"GPU Memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n            # GPU diagnostics\n            torch.cuda.synchronize()\n            print(torch.cuda.memory_summary())\n        start = time.time() #reset time to get final duration\n    return epoch_loss / len(loader)\n\ndef validate(model, val_ids, gcs_preprocessed_path, gcs_precomputed_path, local_dir, labels_df, criterion):\n    model.eval()\n    epoch_loss = 0.0\n    patches_per_volume = 8\n    \n    for tomo_id in tqdm(val_ids, desc=\"Validation\"):\n        # Download tomogram and mask\n        tomo_path = download_npy_from_gcs(tomo_id, gcs_preprocessed_path, \"train\", local_dir)\n        mask_path = download_mask_from_gcs(tomo_id, gcs_precomputed_path, \"train\", local_dir)\n        volume = np.load(tomo_path)\n        mask = np.load(mask_path)\n        \n        # Sample patches\n        patches, mask_patches = sample_patches(tomo_id, volume, mask, labels_df, patches_per_volume=patches_per_volume)\n        dataset = PatchDataset(patches, mask_patches)\n        loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=0, pin_memory=True)\n        \n        # Validate\n        with torch.no_grad():\n            for inputs, targets in loader:\n                inputs = inputs.to(device)\n                targets = targets.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, targets)\n                epoch_loss += loss.item()\n        \n        # Clean up\n        del volume, mask, patches, mask_patches, dataset, loader\n        os.remove(tomo_path)\n        os.remove(mask_path)\n        gc.collect()\n    \n    return epoch_loss / (len(val_ids) * patches_per_volume)\n\n# Training loop\nnum_epochs = 50\npatience = 10\ntrigger_times = 0\npatches_per_volume_train = 64\nbest_val_loss = float(\"inf\")\ntrain_losses = []\nval_losses = []\n\nfor epoch in range(start_epoch, num_epochs):\n    print(f\"STARTING TRAINING\")\n    print(f\"\\n=== Epoch {epoch+1}/{num_epochs} ===\")\n\n    # Training\n    epoch_train_loss = 0.0\n    for tomo_id in tqdm(train_ids, desc=\"Training tomograms\"):\n        # Download tomogram and mask\n        tomo_path = download_npy_from_gcs(tomo_id, gcs_preprocessed_path, \"train\", local_dir)\n        mask_path = download_mask_from_gcs(tomo_id, gcs_precomputed_path, \"train\", local_dir)\n        volume = np.load(tomo_path)\n        mask = np.load(mask_path)\n        \n        # Sample patches\n        patches, mask_patches = sample_patches(tomo_id, volume, mask, labels_df, patches_per_volume=patches_per_volume_train)\n        dataset = PatchDataset(patches, mask_patches)\n        loader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=0, pin_memory=True)\n        \n        # Train\n        epoch_train_loss += train_epoch(model, loader, criterion, optimizer,epoch, start_epoch)\n        \n        # Clean up\n        del volume, mask, patches, mask_patches, dataset, loader\n        os.remove(tomo_path)\n        os.remove(mask_path)\n        gc.collect()\n    \n    train_loss = epoch_train_loss / len(train_ids)\n    train_losses.append(train_loss)\n    \n    # Validation\n    val_loss = validate(model, val_ids, gcs_preprocessed_path, gcs_precomputed_path, local_dir, labels_df, criterion)\n    val_losses.append(val_loss)\n    \n    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n    \n    \n    #wandb.log({                    # Log metrics to wandb\n    #    \"epoch\": epoch + 1,\n    #    \"train_loss\": train_loss,\n    #    \"val_loss\": val_loss,\n    #    \"learning_rate\": optimizer.param_groups[0][\"lr\"]\n    #})\n    scheduler.step(val_loss)   # Learning rate scheduling\n\n    # GPU diagnostics every 10 epochs\n    if (epoch + 1) % 10 == 0:\n        torch.cuda.synchronize()\n        print(f\"\\nðŸ“Š GPU Memory after Epoch {epoch+1}:\")\n        print(torch.cuda.memory_summary())\n        os.system(\"nvidia-smi\")\n\n    \n    # Checkpointing and Early stopping\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        trigger_times = 0\n        torch.save({               # Save full training state \n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'scheduler_state_dict': scheduler.state_dict(),\n            'best_val_loss': best_val_loss\n        }, \"checkpoint.pth\")\n        torch.save(model.state_dict(), \"best_model.pth\") #Save model weights for inference / tuning \n        # Log the best model to wandb - Uncomment the below. \n        #artifact = wandb.Artifact(\"best_model\", type=\"model\")\n        #artifact.add_file(\"best_model.pth\")\n        #wandb.log_artifact(artifact)\n    else:\n        trigger_times += 1\n        if trigger_times >= patience:\n            print(\"Early stopping triggered!\")\n            break\n\n# Plot Training and Validation loss \nplt.figure(figsize=(10, 5))\nplt.plot(train_losses, label=\"Training Loss\")\nplt.plot(val_losses, label=\"Validation Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training and Validation Loss Over Epochs\")\nplt.legend()\nplt.grid(True)\nplt.show()\nplt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T07:38:40.567549Z","iopub.execute_input":"2025-04-23T07:38:40.568256Z","execution_failed":"2025-04-23T07:46:31.176Z"}},"outputs":[{"name":"stdout","text":"No checkpoint found, starting from scratch.\nSTARTING TRAINING\n\n=== Epoch 1/50 ===\n","output_type":"stream"},{"name":"stderr","text":"Training tomograms:   0%|          | 0/518 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Downloading gs://nb153/preprocessed/train/tomo_646049/tomo_646049.npy to /kaggle/working/data/tomo_646049.npy\nâœ… Download complete: tomo_646049\nDownloading gs://nb153/precomputedmasks/train/tomo_646049_mask.npy to /kaggle/working/data/tomo_646049_mask.npy\nâœ… Download complete: tomo_646049_mask.npy\n","output_type":"stream"},{"name":"stderr","text":"\nTraining:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\nTraining:   6%|â–‹         | 1/16 [00:00<00:04,  3.16it/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\nðŸ•’ Batch 0 load time: 0.08s\nInputs shape: torch.Size([4, 1, 128, 128, 128]), min/max: 0.0000/1.0000\nTargets shape: torch.Size([4, 1, 128, 128, 128]), min/max: 0.0000/0.0000\nOutputs shape: torch.Size([4, 1, 128, 128, 128]), min/max: -3.2831/9.0234\nLoss: 1.0000\nGPU Memory: 0.17 GB\n|===========================================================================|\n|                  PyTorch CUDA memory summary, device ID 0                 |\n|---------------------------------------------------------------------------|\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n|===========================================================================|\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n|---------------------------------------------------------------------------|\n| Allocated memory      | 174510 KiB |   1462 MiB |  64401 MiB |  64231 MiB |\n|       from large pool | 158112 KiB |   1444 MiB |  63857 MiB |  63703 MiB |\n|       from small pool |  16398 KiB |     21 MiB |    543 MiB |    527 MiB |\n|---------------------------------------------------------------------------|\n| Active memory         | 174510 KiB |   1462 MiB |  64401 MiB |  64231 MiB |\n|       from large pool | 158112 KiB |   1444 MiB |  63857 MiB |  63703 MiB |\n|       from small pool |  16398 KiB |     21 MiB |    543 MiB |    527 MiB |\n|---------------------------------------------------------------------------|\n| Requested memory      | 173390 KiB |   1458 MiB |  64255 MiB |  64085 MiB |\n|       from large pool | 157056 KiB |   1440 MiB |  63712 MiB |  63559 MiB |\n|       from small pool |  16334 KiB |     21 MiB |    542 MiB |    526 MiB |\n|---------------------------------------------------------------------------|\n| GPU reserved memory   |   1642 MiB |   1642 MiB |   1642 MiB |      0 B   |\n|       from large pool |   1618 MiB |   1618 MiB |   1618 MiB |      0 B   |\n|       from small pool |     24 MiB |     24 MiB |     24 MiB |      0 B   |\n|---------------------------------------------------------------------------|\n| Non-releasable memory |  65105 KiB | 146243 KiB |  20143 MiB |  20079 MiB |\n|       from large pool |  63072 KiB | 142016 KiB |  19578 MiB |  19516 MiB |\n|       from small pool |   2033 KiB |   6133 KiB |    564 MiB |    562 MiB |\n|---------------------------------------------------------------------------|\n| Allocations           |     256    |     319    |    7859    |    7603    |\n|       from large pool |      19    |      63    |    2647    |    2628    |\n|       from small pool |     237    |     296    |    5212    |    4975    |\n|---------------------------------------------------------------------------|\n| Active allocs         |     256    |     319    |    7859    |    7603    |\n|       from large pool |      19    |      63    |    2647    |    2628    |\n|       from small pool |     237    |     296    |    5212    |    4975    |\n|---------------------------------------------------------------------------|\n| GPU reserved segments |      46    |      46    |      46    |       0    |\n|       from large pool |      34    |      34    |      34    |       0    |\n|       from small pool |      12    |      12    |      12    |       0    |\n|---------------------------------------------------------------------------|\n| Non-releasable allocs |      20    |      26    |    2999    |    2979    |\n|       from large pool |       7    |      11    |    1358    |    1351    |\n|       from small pool |      13    |      19    |    1641    |    1628    |\n|---------------------------------------------------------------------------|\n| Oversize allocations  |       0    |       0    |       0    |       0    |\n|---------------------------------------------------------------------------|\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\n|===========================================================================|\n\n","output_type":"stream"},{"name":"stderr","text":"\nTraining:  12%|â–ˆâ–Ž        | 2/16 [00:00<00:04,  3.45it/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\nðŸ•’ Batch 1 load time: 0.05s\nInputs shape: torch.Size([4, 1, 128, 128, 128]), min/max: 0.0000/1.0000\nTargets shape: torch.Size([4, 1, 128, 128, 128]), min/max: 0.0000/0.0000\nOutputs shape: torch.Size([4, 1, 128, 128, 128]), min/max: -3.2592/9.2238\nLoss: 1.0000\nGPU Memory: 0.17 GB\n|===========================================================================|\n|                  PyTorch CUDA memory summary, device ID 0                 |\n|---------------------------------------------------------------------------|\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n|===========================================================================|\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n|---------------------------------------------------------------------------|\n| Allocated memory      | 174510 KiB |   1462 MiB |  68186 MiB |  68016 MiB |\n|       from large pool | 158112 KiB |   1444 MiB |  67611 MiB |  67457 MiB |\n|       from small pool |  16398 KiB |     21 MiB |    575 MiB |    559 MiB |\n|---------------------------------------------------------------------------|\n| Active memory         | 174510 KiB |   1462 MiB |  68186 MiB |  68016 MiB |\n|       from large pool | 158112 KiB |   1444 MiB |  67611 MiB |  67457 MiB |\n|       from small pool |  16398 KiB |     21 MiB |    575 MiB |    559 MiB |\n|---------------------------------------------------------------------------|\n| Requested memory      | 173390 KiB |   1458 MiB |  68031 MiB |  67862 MiB |\n|       from large pool | 157056 KiB |   1440 MiB |  67457 MiB |  67304 MiB |\n|       from small pool |  16334 KiB |     21 MiB |    573 MiB |    557 MiB |\n|---------------------------------------------------------------------------|\n| GPU reserved memory   |   1642 MiB |   1642 MiB |   1642 MiB |      0 B   |\n|       from large pool |   1618 MiB |   1618 MiB |   1618 MiB |      0 B   |\n|       from small pool |     24 MiB |     24 MiB |     24 MiB |      0 B   |\n|---------------------------------------------------------------------------|\n| Non-releasable memory |  65105 KiB | 146243 KiB |  21362 MiB |  21299 MiB |\n|       from large pool |  63072 KiB | 142016 KiB |  20765 MiB |  20703 MiB |\n|       from small pool |   2033 KiB |   6133 KiB |    597 MiB |    595 MiB |\n|---------------------------------------------------------------------------|\n| Allocations           |     256    |     319    |    8325    |    8069    |\n|       from large pool |      19    |      63    |    2802    |    2783    |\n|       from small pool |     237    |     296    |    5523    |    5286    |\n|---------------------------------------------------------------------------|\n| Active allocs         |     256    |     319    |    8325    |    8069    |\n|       from large pool |      19    |      63    |    2802    |    2783    |\n|       from small pool |     237    |     296    |    5523    |    5286    |\n|---------------------------------------------------------------------------|\n| GPU reserved segments |      46    |      46    |      46    |       0    |\n|       from large pool |      34    |      34    |      34    |       0    |\n|       from small pool |      12    |      12    |      12    |       0    |\n|---------------------------------------------------------------------------|\n| Non-releasable allocs |      20    |      26    |    3183    |    3163    |\n|       from large pool |       7    |      11    |    1440    |    1433    |\n|       from small pool |      13    |      19    |    1743    |    1730    |\n|---------------------------------------------------------------------------|\n| Oversize allocations  |       0    |       0    |       0    |       0    |\n|---------------------------------------------------------------------------|\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\n|===========================================================================|\n\n","output_type":"stream"},{"name":"stderr","text":"\nTraining:  19%|â–ˆâ–‰        | 3/16 [00:00<00:03,  3.56it/s]\u001b[A\nTraining:  25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:01<00:03,  3.62it/s]\u001b[A\nTraining:  31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:01<00:03,  3.66it/s]\u001b[A\nTraining:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:01<00:02,  3.69it/s]\u001b[A\nTraining:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:01<00:02,  3.72it/s]\u001b[A\nTraining:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:02<00:02,  3.73it/s]\u001b[A\nTraining:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:02<00:01,  3.74it/s]\u001b[A\nTraining:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 10/16 [00:02<00:01,  3.72it/s]\u001b[A\nTraining:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:02<00:01,  3.72it/s]\u001b[A\nTraining:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:03<00:01,  3.73it/s]\u001b[A\nTraining:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:03<00:00,  3.74it/s]\u001b[A\nTraining:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:03<00:00,  3.75it/s]\u001b[A\nTraining:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:04<00:00,  3.72it/s]\u001b[A\nTraining: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:04<00:00,  3.69it/s]\u001b[A\nTraining tomograms:   0%|          | 1/518 [02:40<23:00:07, 160.17s/it]","output_type":"stream"},{"name":"stdout","text":"Downloading gs://nb153/preprocessed/train/tomo_648adf/tomo_648adf.npy to /kaggle/working/data/tomo_648adf.npy\nâœ… Download complete: tomo_648adf\nDownloading gs://nb153/precomputedmasks/train/tomo_648adf_mask.npy to /kaggle/working/data/tomo_648adf_mask.npy\nâœ… Download complete: tomo_648adf_mask.npy\n","output_type":"stream"},{"name":"stderr","text":"\nTraining:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\nTraining:   6%|â–‹         | 1/16 [00:00<00:04,  3.47it/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\nðŸ•’ Batch 0 load time: 0.05s\nInputs shape: torch.Size([4, 1, 128, 128, 128]), min/max: 0.0000/1.0000\nTargets shape: torch.Size([4, 1, 128, 128, 128]), min/max: 0.0000/0.0000\nOutputs shape: torch.Size([4, 1, 128, 128, 128]), min/max: -8.7975/17.3237\nLoss: 1.0000\nGPU Memory: 0.17 GB\n|===========================================================================|\n|                  PyTorch CUDA memory summary, device ID 0                 |\n|---------------------------------------------------------------------------|\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n|===========================================================================|\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n|---------------------------------------------------------------------------|\n| Allocated memory      | 174510 KiB |   1462 MiB | 124965 MiB | 124794 MiB |\n|       from large pool | 158112 KiB |   1444 MiB | 123920 MiB | 123766 MiB |\n|       from small pool |  16398 KiB |     21 MiB |   1044 MiB |   1028 MiB |\n|---------------------------------------------------------------------------|\n| Active memory         | 174510 KiB |   1462 MiB | 124965 MiB | 124794 MiB |\n|       from large pool | 158112 KiB |   1444 MiB | 123920 MiB | 123766 MiB |\n|       from small pool |  16398 KiB |     21 MiB |   1044 MiB |   1028 MiB |\n|---------------------------------------------------------------------------|\n| Requested memory      | 173390 KiB |   1458 MiB | 124678 MiB | 124509 MiB |\n|       from large pool | 157056 KiB |   1440 MiB | 123636 MiB | 123483 MiB |\n|       from small pool |  16334 KiB |     21 MiB |   1041 MiB |   1025 MiB |\n|---------------------------------------------------------------------------|\n| GPU reserved memory   |   1642 MiB |   1642 MiB |   1642 MiB |      0 B   |\n|       from large pool |   1618 MiB |   1618 MiB |   1618 MiB |      0 B   |\n|       from small pool |     24 MiB |     24 MiB |     24 MiB |      0 B   |\n|---------------------------------------------------------------------------|\n| Non-releasable memory |  65105 KiB | 146243 KiB |  39673 MiB |  39610 MiB |\n|       from large pool |  63072 KiB | 142016 KiB |  38585 MiB |  38523 MiB |\n|       from small pool |   2033 KiB |   6133 KiB |   1088 MiB |   1086 MiB |\n|---------------------------------------------------------------------------|\n| Allocations           |     256    |     319    |   15063    |   14807    |\n|       from large pool |      19    |      63    |    5127    |    5108    |\n|       from small pool |     237    |     296    |    9936    |    9699    |\n|---------------------------------------------------------------------------|\n| Active allocs         |     256    |     319    |   15063    |   14807    |\n|       from large pool |      19    |      63    |    5127    |    5108    |\n|       from small pool |     237    |     296    |    9936    |    9699    |\n|---------------------------------------------------------------------------|\n| GPU reserved segments |      46    |      46    |      46    |       0    |\n|       from large pool |      34    |      34    |      34    |       0    |\n|       from small pool |      12    |      12    |      12    |       0    |\n|---------------------------------------------------------------------------|\n| Non-releasable allocs |      20    |      26    |    5838    |    5818    |\n|       from large pool |       7    |      11    |    2671    |    2664    |\n|       from small pool |      13    |      19    |    3167    |    3154    |\n|---------------------------------------------------------------------------|\n| Oversize allocations  |       0    |       0    |       0    |       0    |\n|---------------------------------------------------------------------------|\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\n|===========================================================================|\n\n","output_type":"stream"},{"name":"stderr","text":"\nTraining:  12%|â–ˆâ–Ž        | 2/16 [00:00<00:03,  3.52it/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\nðŸ•’ Batch 1 load time: 0.06s\nInputs shape: torch.Size([4, 1, 128, 128, 128]), min/max: 0.0000/1.0000\nTargets shape: torch.Size([4, 1, 128, 128, 128]), min/max: 0.0000/0.0000\nOutputs shape: torch.Size([4, 1, 128, 128, 128]), min/max: -4.0778/10.1088\nLoss: 1.0000\nGPU Memory: 0.17 GB\n|===========================================================================|\n|                  PyTorch CUDA memory summary, device ID 0                 |\n|---------------------------------------------------------------------------|\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n|===========================================================================|\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n|---------------------------------------------------------------------------|\n| Allocated memory      | 174510 KiB |   1462 MiB | 128750 MiB | 128580 MiB |\n|       from large pool | 158112 KiB |   1444 MiB | 127674 MiB | 127520 MiB |\n|       from small pool |  16398 KiB |     21 MiB |   1075 MiB |   1059 MiB |\n|---------------------------------------------------------------------------|\n| Active memory         | 174510 KiB |   1462 MiB | 128750 MiB | 128580 MiB |\n|       from large pool | 158112 KiB |   1444 MiB | 127674 MiB | 127520 MiB |\n|       from small pool |  16398 KiB |     21 MiB |   1075 MiB |   1059 MiB |\n|---------------------------------------------------------------------------|\n| Requested memory      | 173390 KiB |   1458 MiB | 128455 MiB | 128285 MiB |\n|       from large pool | 157056 KiB |   1440 MiB | 127382 MiB | 127228 MiB |\n|       from small pool |  16334 KiB |     21 MiB |   1073 MiB |   1057 MiB |\n|---------------------------------------------------------------------------|\n| GPU reserved memory   |   1642 MiB |   1642 MiB |   1642 MiB |      0 B   |\n|       from large pool |   1618 MiB |   1618 MiB |   1618 MiB |      0 B   |\n|       from small pool |     24 MiB |     24 MiB |     24 MiB |      0 B   |\n|---------------------------------------------------------------------------|\n| Non-releasable memory |  65105 KiB | 146243 KiB |  40893 MiB |  40829 MiB |\n|       from large pool |  63072 KiB | 142016 KiB |  39771 MiB |  39710 MiB |\n|       from small pool |   2033 KiB |   6133 KiB |   1121 MiB |   1119 MiB |\n|---------------------------------------------------------------------------|\n| Allocations           |     256    |     319    |   15529    |   15273    |\n|       from large pool |      19    |      63    |    5282    |    5263    |\n|       from small pool |     237    |     296    |   10247    |   10010    |\n|---------------------------------------------------------------------------|\n| Active allocs         |     256    |     319    |   15529    |   15273    |\n|       from large pool |      19    |      63    |    5282    |    5263    |\n|       from small pool |     237    |     296    |   10247    |   10010    |\n|---------------------------------------------------------------------------|\n| GPU reserved segments |      46    |      46    |      46    |       0    |\n|       from large pool |      34    |      34    |      34    |       0    |\n|       from small pool |      12    |      12    |      12    |       0    |\n|---------------------------------------------------------------------------|\n| Non-releasable allocs |      20    |      26    |    6022    |    6002    |\n|       from large pool |       7    |      11    |    2753    |    2746    |\n|       from small pool |      13    |      19    |    3269    |    3256    |\n|---------------------------------------------------------------------------|\n| Oversize allocations  |       0    |       0    |       0    |       0    |\n|---------------------------------------------------------------------------|\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\n|===========================================================================|\n\n","output_type":"stream"},{"name":"stderr","text":"\nTraining:  19%|â–ˆâ–‰        | 3/16 [00:00<00:03,  3.58it/s]\u001b[A\nTraining:  25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:01<00:03,  3.65it/s]\u001b[A\nTraining:  31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:01<00:02,  3.74it/s]\u001b[A\nTraining:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:01<00:02,  3.73it/s]\u001b[A\nTraining:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:01<00:02,  3.72it/s]\u001b[A\nTraining:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:02<00:02,  3.73it/s]\u001b[A\nTraining:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:02<00:01,  3.74it/s]\u001b[A\nTraining:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 10/16 [00:02<00:01,  3.70it/s]\u001b[A\nTraining:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:02<00:01,  3.71it/s]\u001b[A\nTraining:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:03<00:01,  3.72it/s]\u001b[A\nTraining:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:03<00:00,  3.73it/s]\u001b[A\nTraining:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:03<00:00,  3.73it/s]\u001b[A\nTraining:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:04<00:00,  3.74it/s]\u001b[A\nTraining: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:04<00:00,  3.70it/s]\u001b[A\nTraining tomograms:   0%|          | 2/518 [06:13<27:25:04, 191.29s/it]","output_type":"stream"},{"name":"stdout","text":"Downloading gs://nb153/preprocessed/train/tomo_3c6038/tomo_3c6038.npy to /kaggle/working/data/tomo_3c6038.npy\nâœ… Download complete: tomo_3c6038\nDownloading gs://nb153/precomputedmasks/train/tomo_3c6038_mask.npy to /kaggle/working/data/tomo_3c6038_mask.npy\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# 1 Hyperparameter Tuning (Peak Detection Threshold)\n# 2 Predict on the validation set,\n# 3 Extract motor locations using peak detection\n# 4 Tune the threshold to maximize the FÎ²-score (Î²=2).\n# 5 Using competition's metric\n\n# Metric implementation (from provided notebook)\ndef distance_metric(solution, submission, thresh_ratio, min_radius):\n    coordinate_cols = ['Motor axis 0', 'Motor axis 1', 'Motor axis 2']\n    label_tensor = solution[coordinate_cols].values.reshape(len(solution), -1, len(coordinate_cols))\n    predicted_tensor = submission[coordinate_cols].values.reshape(len(submission), -1, len(coordinate_cols))\n    solution['distance'] = np.linalg.norm(label_tensor - predicted_tensor, axis=2).min(axis=1)\n    solution['thresholds'] = solution['Voxel spacing'].apply(lambda x: (min_radius * thresh_ratio) / x)\n    solution['predictions'] = submission['Has motor'].values\n    solution.loc[(solution['distance'] > solution['thresholds']) & (solution['Has motor'] == 1) & (submission['Has motor'] == 1), 'predictions'] = 0\n    return solution['predictions'].values\n\ndef score(solution, submission, min_radius, beta):\n    solution = solution.sort_values('tomo_id').reset_index(drop=True)\n    submission = submission.sort_values('tomo_id').reset_index(drop=True)\n    if not solution['tomo_id'].eq(submission['tomo_id']).all():\n        raise ValueError('Submitted tomo_id values do not match')\n    submission['Has motor'] = 1\n    select = (submission[['Motor axis 0', 'Motor axis 1', 'Motor axis 2']] == -1).any(axis='columns')\n    submission.loc[select, 'Has motor'] = 0\n    predictions = distance_metric(solution, submission, thresh_ratio=1.0, min_radius=min_radius)\n    return sklearn.metrics.fbeta_score(solution['Has motor'].values, predictions, beta=beta)\n\n# Predict on full volume with sliding window\ndef predict_full_volume(model, volume, patch_size=(128, 128, 128), stride=64):\n    model.eval()\n    volume = volume.to(device)\n    z_size, y_size, x_size = volume.shape[2:]\n    pz, py, px = patch_size\n    output = torch.zeros_like(volume)\n    counts = torch.zeros_like(volume)\n    \n    with torch.no_grad():\n        for z in range(0, z_size, stride):\n            for y in range(0, y_size, stride):\n                for x in range(0, x_size, stride):\n                    z_end, y_end, x_end = z+pz, y+py, x+px\n                    patch = volume[:, :, z:min(z_end, z_size), y:min(y_end, y_size), x:min(x_end, x_size)]\n                    pad_z, pad_y, pad_x = max(0, z_end-z_size), max(0, y_end-y_size), max(0, x_end-x_size)\n                    if pad_z > 0 or pad_y > 0 or pad_x > 0:\n                        patch = torch.nn.functional.pad(patch, (0, pad_x, 0, pad_y, 0, pad_z))\n                    out_patch = torch.sigmoid(model(patch))\n                    output[:, :, z:min(z_end, z_size), y:min(y_end, y_size), x:min(x_end, x_size)] += out_patch[:, :, :pz-pad_z, :py-pad_y, :px-pad_x]\n                    counts[:, :, z:min(z_end, z_size), y:min(y_end, y_size), x:min(x_end, x_size)] += 1\n    output = output / (counts + 1e-8)\n    return output.cpu().numpy()\n\n# Extract motor location from predicted mask\ndef extract_motor_location(mask, threshold):\n    mask = mask.squeeze()\n    if mask.max() < threshold:\n        return -1, -1, -1, 0  # No motor\n    # Find the strongest peak\n    z, y, x = np.unravel_index(np.argmax(mask), mask.shape)\n    # Refine with center of mass for sub-voxel accuracy\n    region = mask[max(0, z-5):z+6, max(0, y-5):y+6, max(0, x-5):x+6]\n    if region.size == 0:\n        return z, y, x, 1\n    z_offset, y_offset, x_offset = center_of_mass(region)\n    z, y, x = z + z_offset - 5, y + y_offset - 5, x + x_offset - 5\n    return z, y, x, 1\n\n# Tune peak detection threshold\ndef tune_threshold(model, val_loader, val_ids, labels_df, thresholds=np.linspace(0.1, 0.9, 9)):\n    model.load_state_dict(torch.load(\"best_model.pth\"))\n    model.eval()\n    best_threshold = 0.5\n    best_fbeta = 0.0\n    # Store thresholds and FÎ² Scrores \n    thresholds_list = []\n    fbeta_scores = []\n    \n    for threshold in thresholds:\n        predictions = []\n        for tomo_id in tqdm(val_ids, desc=f\"Tuning threshold {threshold:.2f}\"):\n            dataset = TomogramnDataset(tomo_id, gcs_preprocessed_path, local_dir, mode=\"val\")\n            dataset.load()\n            volume, _ = dataset[0]\n            pred_mask = predict_full_volume(model, volume)\n            z, y, x, has_motor = extract_motor_location(pred_mask, threshold)  # Extract motor location\n            \n            # Dont Load full volume - Use self.volumes from dataset instead of load tomogram\n            #volume = val_dataset.volumes[tomo_id]\n            #volume = torch.tensor(volume[np.newaxis, np.newaxis, ...], dtype=torch.float32)\n            #pred_mask = predict_full_volume(model, volume)  # Predict mask          \n            #z, y, x, has_motor = extract_motor_location(pred_mask, threshold)  # Extract motor location\n            \n            # Visualize prediction for the first tomogram \n            if len(predictions) == 0 and tomo_id == val_ids[0]: # Only for the first tomogram \n                # load ground truth mask \n                mask_path = download_mask_from_gcs(tomo_id, gcs_precomputed_path, \"train\", local_dir)\n                gt_mask = np.load(mask_path)\n                # Take a middle slice\n                slice_idx = volume.shape[2] // 2\n                tomo_slice = volume[0, 0, slice_idx, :, :].numpy()\n                pred_slice = pred_mask[0, 0, slice_idx, :, :]\n                gt_slice = gt_mask[slice_idx, :, :]\n                # Get predicted and ground truth motor locations\n                pred_z, pred_y, pred_x, _ = z, y, x, has_motor\n                gt_row = labels_df[labels_df[\"tomo_id\"] == tomo_id].iloc[0]\n                gt_z, gt_y, gt_x = gt_row[\"Motor axis 0\"], gt_row[\"Motor axis 1\"], gt_row[\"Motor axis 2\"]\n\n                plt.figure(figsize=(15, 5))\n                plt.subplot(1, 3, 1)\n                plt.imshow(tomo_slice, cmap=\"gray\")\n                plt.title(f\"Tomogram Slice (z={slice_idx})\")\n                plt.axis(\"off\")     \n                plt.subplot(1, 3, 2)\n                plt.imshow(pred_slice, cmap=\"hot\")\n                if has_motor:\n                    plt.scatter(pred_x, pred_y, c=\"blue\", marker=\"x\", s=100, label=\"Predicted\")\n                if gt_z != -1:\n                    plt.scatter(gt_x, gt_y, c=\"green\", marker=\"o\", s=100, label=\"Ground Truth\")\n                plt.title(\"Predicted Mask with Motor Locations\")\n                plt.legend()\n                plt.axis(\"off\")\n                plt.subplot(1, 3, 3)\n                plt.imshow(gt_slice, cmap=\"hot\")\n                if gt_z != -1:\n                    plt.scatter(gt_x, gt_y, c=\"green\", marker=\"o\", s=100, label=\"Ground Truth\")\n                plt.title(\"Ground Truth Mask\")\n                plt.legend()\n                plt.axis(\"off\")\n                plt.tight_layout()\n                plt.show()\n                break  # Only visualize one tomogram\n            predictions.append({\"tomo_id\": tomo_id, \"Motor axis 0\": z, \"Motor axis 1\": y, \"Motor axis 2\": x, \"Has motor\": has_motor})\n        \n        # Create submission DataFrame\n        submission_df = pd.DataFrame(predictions)\n        # Create solution DataFrame\n        solution_data = []\n        for tomo_id in val_ids:\n            tomo_labels = labels_df[labels_df[\"tomo_id\"] == tomo_id].iloc[0]\n            solution_data.append({\n                \"tomo_id\": tomo_id,\n                \"Motor axis 0\": tomo_labels[\"Motor axis 0\"],\n                \"Motor axis 1\": tomo_labels[\"Motor axis 1\"],\n                \"Motor axis 2\": tomo_labels[\"Motor axis 2\"],\n                \"Voxel spacing\": tomo_labels[\"Voxel spacing\"],\n                \"Has motor\": 1 if tomo_labels[\"Number of motors\"] > 0 else 0\n            })\n        solution_df = pd.DataFrame(solution_data)\n        # Compute FÎ²-score\n        fbeta = score(solution_df, submission_df, min_radius=1000, beta=2)\n        print(f\"Threshold {threshold:.2f}, FÎ²-score: {fbeta:.4f}\")\n        # Append for plotting \n        thresholds_list.append(threshold)\n        fbeta_scores.append(fbeta)\n        # WANDB Log FÎ²-score for this threshold\n        \"\"\"\n        wandb.log({\n            \"threshold\": threshold,\n            \"fbeta_score\": fbeta\n        })\n        \"\"\"\n        if fbeta > best_fbeta:\n            best_fbeta = fbeta\n            best_threshold = threshold\n\n    # Plot FÎ²-score vs. threshold\n    plt.figure(figsize=(8, 5))\n    plt.plot(thresholds_list, fbeta_scores, marker=\"o\")\n    plt.xlabel(\"Threshold\")\n    plt.ylabel(\"FÎ²-score (Î²=2)\")\n    plt.title(\"FÎ²-score vs. Peak Detection Threshold\")\n    plt.grid(True)\n    plt.show()\n    plt.close()\n    print(f\"Best threshold: {best_threshold:.2f}, Best FÎ²-score: {best_fbeta:.4f}\")\n    return best_threshold\n\n\n\n# Log the best threshold and FÎ²-score\n#wandb.log({\n#    \"best_threshold\": best_threshold,\n#    \"best_fbeta_score\": best_fbeta\n#})\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test prediction\ndef predict_test(model, test_ids, gcs_preprocessed_path, local_dir, threshold):\n    model.load_state_dict(torch.load(\"best_model.pth\"))\n    model.eval()\n    predictions = []\n    for tomo_id in tqdm(test_ids, desc=\"Predicting on test set\"):\n        dataset = TomogramDataset(tomo_id, gcs_preprocessed_path, local_dir, mode=\"test\")\n        dataset.load()\n        volume, _ = dataset[0]\n        pred_mask = predict_full_volume(model, volume)\n        z, y, x, has_motor = extract_motor_location(pred_mask, threshold)\n        predictions.append({\"tomo_id\": tomo_id, \"Motor axis 0\": z, \"Motor axis 1\": y, \"Motor axis 2\": x})\n        dataset.clear()\n    return pd.DataFrame(predictions)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Run pipeline\nprint(\"Starting hyperparameter tuning...\")\nbest_threshold = tune_threshold(model, val_ids, gcs_preprocessed_path, gcs_precomputed_path, local_dir, labels_df)\nprint(\"Generating test predictions...\")\nsubmission_df = predict_test(model, test_ids, gcs_preprocessed_path, local_dir, best_threshold)\nsubmission_df.to_csv(\"submission.csv\", index=False)\nprint(\"Submission file created: submission.csv\")\n\n# Finish the wandb run\n#wandb.finish()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}